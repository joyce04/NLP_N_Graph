{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref\n",
    "- https://github.com/philipperemy/keras-attention-mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can attention model figure out dependent variable\n",
    "# ex) v = vector with 32 values\n",
    "# v[1] == target & all other values are randomly chosen\n",
    "# can the model understand the importance of v[1]?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import *\n",
    "from keras.layers import Input, Dense, multiply\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_c = 10000\n",
    "input_dims = 32\n",
    "attention_column = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(model, inputs, print_shape_only=False, layer_name=None):\n",
    "    activations = []\n",
    "#     inp =  model.input\n",
    "    if layer_name is None:\n",
    "        outputs = [layer.output for layer in model.layers]\n",
    "    else:\n",
    "        outputs = [layer.output for layer in model.layers if layer.name==layer_name]\n",
    "#     print(model.layers)\n",
    "#     print(outputs)\n",
    "    funcs = [K.function([model.input] + [K.learning_phase()], [out]) for out in outputs]\n",
    "    layer_outputs = [func([inputs, 1.])[0] for func in funcs]\n",
    "    for layer_activations in layer_outputs:\n",
    "        activations.append(layer_activations)\n",
    "        if print_shape_only:\n",
    "            print(layer_activations.shape)\n",
    "        else:\n",
    "            print(layer_activations)\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_date(batch_size, input_size, attention_index):\n",
    "    train_x = np.random.standard_normal(size=(batch_size, input_size))\n",
    "    train_y = np.random.randint(low=0, high=2, size=(batch_size, 1))\n",
    "    train_x[:, attention_index] = train_y[:, 0]\n",
    "    return (train_x, train_y)\n",
    "\n",
    "train_x, train_y = generate_date(data_c, input_dims, attention_column)\n",
    "test_x, test_y = generate_date(1, input_dims, attention_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense- Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # input layer\n",
    "    input_layer = Input(shape=(input_dims,))\n",
    "    \n",
    "    # attention layer\n",
    "    attention_prob = Dense(input_dims, activation='softmax', name='attention_vec')(input_layer)\n",
    "    attention_mul = multiply([input_layer, attention_prob])\n",
    "    \n",
    "    # fully connected layer\n",
    "    y = Dense(64)(attention_mul)\n",
    "    y = Dense(1, activation='sigmoid')(y)\n",
    "    \n",
    "    model = Model(input_layer, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/madigun/.pyenv/versions/3.6.7/envs/grace_jupyter/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Dense)           (None, 32)           1056        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 32)           0           input_1[0][0]                    \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           2112        multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            65          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,233\n",
      "Trainable params: 3,233\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/madigun/.pyenv/versions/3.6.7/envs/grace_jupyter/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.6775 - acc: 0.6259 - val_loss: 0.6452 - val_acc: 0.7000\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.5721 - acc: 0.7490 - val_loss: 0.4913 - val_acc: 0.7860\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.4088 - acc: 0.8345 - val_loss: 0.3253 - val_acc: 0.8845\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.2351 - acc: 0.9237 - val_loss: 0.1567 - val_acc: 0.9550\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0889 - acc: 0.9845 - val_loss: 0.0473 - val_acc: 0.9910\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0224 - acc: 0.9988 - val_loss: 0.0135 - val_acc: 0.9995\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbc80db4da0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=10, batch_size=64, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(test_x, test_y, batch_size=64, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004313574463594705"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7fbc81bdaf98>,\n",
       " <keras.layers.core.Dense at 0x7fbc819286a0>,\n",
       " <keras.layers.merge.Multiply at 0x7fbc81928240>,\n",
       " <keras.layers.core.Dense at 0x7fbc819284a8>,\n",
       " <keras.layers.core.Dense at 0x7fbc8194db38>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get attention vector\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32)\n"
     ]
    }
   ],
   "source": [
    "attention_vector = get_activations(model, test_x, print_shape_only=True, layer_name='attention_vec')[0].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01689882, 0.01737297, 0.03170816, 0.01617951, 0.04984336,\n",
       "       0.03372724, 0.02441747, 0.16139495, 0.02261229, 0.01316772,\n",
       "       0.03093454, 0.02138949, 0.03498478, 0.0280783 , 0.03912384,\n",
       "       0.02170597, 0.03091755, 0.01832805, 0.01956346, 0.01720782,\n",
       "       0.10320486, 0.03046456, 0.02861659, 0.02076909, 0.01330648,\n",
       "       0.01963806, 0.0172387 , 0.01316991, 0.02872724, 0.02870503,\n",
       "       0.01235922, 0.03424392], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbc8015ec50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(attention_vector, columns=['attention (%)']).plot(figsize=(10, 6), kind='bar', title='attention vector')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM - Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_c = 300000\n",
    "input_dims = 2\n",
    "time_steps = 20\n",
    "# true = attention vector is shared across the input_dimensions\n",
    "SINGEL_ATTENTION_VECTOR = False\n",
    "\n",
    "# APPLY_ATTENTION_BEFORE_LSTM = False\n",
    "APPLY_ATTENTION_BEFORE_LSTM = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recurrent_data(batch_size, time_steps, input_dims, attention_column=10):\n",
    "    train_x = np.random.standard_normal(size=(batch_size, time_steps, input_dims))\n",
    "    train_y = np.random.randint(low=0, high=2, size=(batch_size, 1))\n",
    "    train_x[:, attention_column, :] = np.tile(train_y[:], (1, input_dims))\n",
    "    return train_x, train_y\n",
    "\n",
    "train_rx, train_ry = generate_recurrent_data(data_c, time_steps, input_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_3d_block(time_steps, input_layer, single_attention_vector):\n",
    "    input_dim = int(input_layer.shape[2])\n",
    "    a = Permute((2, 1))(input_layer)\n",
    "    a = Reshape((input_dim, time_steps))(a)\n",
    "    a = Dense(time_steps, activation='softmax')(a)\n",
    "    if single_attention_vector:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "        a = RepeatVector(input_dim)(a)\n",
    "    \n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "#     a_probs = Permute((2, 1))(a)\n",
    "    output_attention_mul = multiply([input_layer, a_probs], name='attention_mul')\n",
    "#     output_attention_mul = multiply([input_layer, a_probs])\n",
    "    return output_attention_mul\n",
    "    \n",
    "#     https://github.com/philipperemy/keras-attention-mechanism/blob/master/attention_lstm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply on inputs\n",
    "def model_atten_before_lstm(time_steps, input_dims):\n",
    "    input_layer = Input(shape=(time_steps, input_dims))\n",
    "    attention_mul = attention_3d_block(time_steps, input_layer, SINGEL_ATTENTION_VECTOR)\n",
    "    lstm_units = 32\n",
    "    attention_mul = LSTM(lstm_units, return_sequences=True)(attention_mul)\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    model = Model(input=[input_layer], output=output)\n",
    "    return model\n",
    "\n",
    "# apply on outputs\n",
    "def model_atten_after_lstm(time_steps, input_dims):\n",
    "    input_layer = Input(shape=(time_steps, input_dims, ))\n",
    "    lstm_units = 32\n",
    "    lstm_out = LSTM(lstm_units, return_sequences=True)(input_layer)\n",
    "    attention_mul = attention_3d_block(time_steps, lstm_out, SINGEL_ATTENTION_VECTOR)\n",
    "    attention_mul  = Flatten()(attention_mul)\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    model = Model(input=[input_layer], output=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/madigun/.pyenv/versions/3.6.7/envs/grace_jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "if APPLY_ATTENTION_BEFORE_LSTM:\n",
    "    model = model_atten_before_lstm(time_steps, input_dims)\n",
    "else:\n",
    "    model = model_atten_after_lstm(time_steps, input_dims)\n",
    "    \n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 20, 2)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 2, 20)        0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 2, 20)        0           permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2, 20)        420         reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Permute)         (None, 20, 2)        0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_mul (Multiply)        (None, 20, 2)        0           input_2[0][0]                    \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 20, 32)       4480        attention_mul[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 20, 1)        33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,933\n",
      "Trainable params: 4,933\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20, 2)\n",
      "attention =  [-0.05047991 -0.00162791 -0.037816   -0.01665853 -0.00303603 -0.06609426\n",
      " -0.01130904 -0.00931512 -0.00420064  0.02398755  0.05528329 -0.00245764\n",
      "  0.2958654   0.01233708  0.04457321 -0.01258763  0.07020381  0.01963383\n",
      " -0.01422871  0.00290396]\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "attention =  [-0.03533969  0.0246401  -0.00700516 -0.00271032  0.04707222 -0.00416335\n",
      "  0.00270275  0.02283018  0.03365798  0.0570839   0.         -0.01785267\n",
      " -0.03114893 -0.0518785  -0.02901185 -0.02222406 -0.01563965  0.01455854\n",
      " -0.025893    0.01338897]\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "attention =  [-0.01344921  0.00235358 -0.04176329 -0.1459367  -0.00947844  0.01427691\n",
      "  0.02516806 -0.0159712  -0.01055146 -0.06630018  0.          0.01721878\n",
      " -0.12676843  0.04387463 -0.01418864  0.0082344   0.00877747  0.00686299\n",
      " -0.01056548 -0.00725886]\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "attention =  [-0.02289453 -0.0018416  -0.00984958 -0.00767971 -0.02473009 -0.01404429\n",
      " -0.02404571  0.02387759 -0.05266433 -0.01755241  0.         -0.01581258\n",
      " -0.02481593 -0.00894433 -0.01904716  0.02452868  0.02825245  0.00470702\n",
      "  0.0132734   0.0240137 ]\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "attention =  [-0.09245759 -0.02437807  0.01357461 -0.02182626 -0.00358232  0.06120028\n",
      " -0.02756603  0.02418732  0.01696907  0.06232468  0.          0.00366089\n",
      " -0.03004107 -0.01199253  0.01349421  0.01643945  0.00181814 -0.0004367\n",
      " -0.0196473  -0.00114007]\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "attention =  [-0.01810112  0.00211079  0.00089197  0.01151251 -0.03595388 -0.02263347\n",
      "  0.00171555 -0.00809218  0.01122199  0.04897642  0.          0.02785493\n",
      "  0.0367366  -0.04262277  0.00542244 -0.04414349 -0.0086218   0.00908662\n",
      "  0.0158181  -0.00608383]\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n",
      "(1, 20, 2)\n"
     ]
    }
   ],
   "source": [
    "attention_vectors = []\n",
    "for i in range(300):\n",
    "    test_rx, test_ry = generate_recurrent_data(1, time_steps, input_dims)\n",
    "    attention_vector = np.mean(get_activations(model, test_rx, print_shape_only=True, layer_name='attention_mul')[0], axis=2).squeeze()\n",
    "    if i % 50 ==0:\n",
    "        print('attention = ', attention_vector)\n",
    "        assert(np.sum(attention_vector)-1.0) < 1e-5\n",
    "    attention_vectors.append(attention_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01180851,  0.00585801, -0.01409213, -0.02533209, -0.00676676,\n",
       "        0.00494408, -0.00210614,  0.00672438,  0.01409456,  0.00407073,\n",
       "        0.0303301 ,  0.0123538 , -0.01600493,  0.01308461,  0.00420127,\n",
       "       -0.00927497, -0.0078468 , -0.00122156, -0.01200515, -0.00425543],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_vector_final = np.mean(np.array(attention_vectors), axis=0)\n",
    "attention_vector_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbc780ae6d8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(attention_vector_final, columns=['attention (%)']).plot(kind='bar',\n",
    "                                                                    title='Attention mechanism as a function of input dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grace_python",
   "language": "python",
   "name": "grace_jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
