{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy for Entity Recognition\n",
    "\n",
    "References :\n",
    "- https://spacy.io/usage/visualizers\n",
    "- https://explosion.ai/blog/deep-learning-formula-nlp\n",
    "- https://spacy.io/usage/training#ner\n",
    "\n",
    "- video \n",
    "https://www.youtube.com/watch?v=l4scwf8KeIA\n",
    "- training \n",
    "https://towardsdatascience.com/a-review-of-named-entity-recognition-ner-using-automatic-summarization-of-resumes-5248a75de175"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating training dataset\n",
    "\n",
    "- format\n",
    "    - (\"Uber blew through $1 million a week\", {'entities':[(0, 4, 'ORG')]}), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieve sample table data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import db_conn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = db_conn.get_connection()\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "select lower(table_title) from article_tables;\n",
    "\"\"\")\n",
    "titles = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = list(map(lambda x: x[0], titles))\n",
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retrieve all drug names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "SELECT distinct(lower(cui1_str)) FROM dict_collapsed_final;\n",
    "\"\"\")\n",
    "d1 = cur.fetchall()\n",
    "d1 = pd.DataFrame(d1)\n",
    "d1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "SELECT distinct(lower(cui2_str)) FROM dict_collapsed_final;\n",
    "\"\"\")\n",
    "d2 = cur.fetchall()\n",
    "d2 = pd.DataFrame(d2)\n",
    "d2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = d1.append(d2)\n",
    "drugs.columns = ['name']\n",
    "drugs.drop_duplicates(inplace=True)\n",
    "drugs.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs.to_csv('./drug_dictionary.csv', sep=',', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retrieve all Side effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "SELECT distinct(lower(llt_name)) from meddra_llt_181022;\n",
    "\"\"\")\n",
    "sd = pd.DataFrame(cur.fetchall())\n",
    "sd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.columns = ['name']\n",
    "sd.drop_duplicates(inplace=True)\n",
    "sd.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find drug names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flashtext import KeywordProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_keyword_processor = KeywordProcessor(case_sensitive=False)\n",
    "for i, r in drugs.iterrows():\n",
    "    drug_keyword_processor.add_keyword(r['name'].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_keyword_processor = KeywordProcessor(case_sensitive=False)\n",
    "for i, sd in sd.iterrows():\n",
    "    ad_keyword_processor.add_keyword(sd['name'].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_entities = []\n",
    "no_entities = []\n",
    "for ti in titles:\n",
    "    found = drug_keyword_processor.extract_keywords(ti.strip())\n",
    "    ad_found = ad_keyword_processor.extract_keywords(ti.strip())\n",
    "    ents = [] \n",
    "    for f in found:\n",
    "        if ti.find(f)>=0:\n",
    "            ents.append((ti.find(f), ti.find(f)+len(f), 'DRUG'))\n",
    "        \n",
    "    for f in ad_found:\n",
    "        if ti.find(f)>=0:\n",
    "            ents.append((ti.find(f), ti.find(f)+len(f), 'SIDE_EFFECT'))\n",
    "        \n",
    "    if len(ents)>0:\n",
    "        c_entities.append((ti, {'entities':ents}))\n",
    "    else:\n",
    "        no_entities.append((ti, {'entities':[]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(c_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(no_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_entities[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_list = c_entities + no_entities[:len(c_entities)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference : https://spacy.io/usage/training#train-entity  \n",
    "\n",
    "- prediction is based on the examples the model has seen during training.\n",
    "- not memorizing -> why the training data should be representative of the data we want to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(model)  # load existing spaCy model\n",
    "# print(\"Loaded model '%s'\" % model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add entity recognizer to model if it's not in the pipeline\n",
    "# nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "if 'ner' not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe('ner')\n",
    "    nlp.add_pipe(ner)\n",
    "# otherwise, get it, so we can add labels to it\n",
    "else:\n",
    "    ner = nlp.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner.add_label('DRUG') \n",
    "ner.add_label('SIDE_EFFECT')\n",
    "# add new entity label to entity recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = nlp.entity.create_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get names of other pipes to disable them during training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "    for itn in range(10):\n",
    "        random.shuffle(com_list)\n",
    "        losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        batches = minibatch(com_list, size=compounding(4., 32., 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=0.1,#0.35,\n",
    "                       losses=losses)\n",
    "        print('Losses', losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the trained model\n",
    "no_entities[3500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_text = 'comparisons of responses to graded dobutamine infusion, y versus o'\n",
    "test_text = 'Cosentyx, trade name Secukinumab, is a human antibody that binds to the protein interleukin (IL)-17A, and is marketed by Novartis for the treatment of psoriasis, ankylosing spondylitis, and psoriatic arthritis.'\n",
    "# test_text = no_entities[3500][0]\n",
    "doc = nlp(test_text)\n",
    "print(\"Entities in '%s'\" % test_text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to output directory\n",
    "\n",
    "# output_dir = Path('./')\n",
    "# if not output_dir.exists():\n",
    "#     output_dir.mkdir()\n",
    "# nlp.meta['name'] = new_model_name  # rename model\n",
    "# nlp.to_disk(output_dir)\n",
    "# print(\"Saved model to\", output_dir)\n",
    "\n",
    "# # test the saved model\n",
    "# print(\"Loading from\", output_dir)\n",
    "# nlp2 = spacy.load(output_dir)\n",
    "# doc2 = nlp2(test_text)\n",
    "# for ent in doc2.ents:\n",
    "#     print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
