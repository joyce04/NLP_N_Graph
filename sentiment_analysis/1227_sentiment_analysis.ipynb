{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with RNN\n",
    "\n",
    "Reference:\n",
    "- https://towardsdatascience.com/a-beginners-guide-on-sentiment-analysis-with-rnn-9e100627c02e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/grace/workspace/keras/venv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/grace/workspace/keras/venv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = imdb.get_word_index()\n",
    "id2word = {i: word for word, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'and',\n",
       " 'full',\n",
       " 'involving',\n",
       " 'to',\n",
       " 'impressive',\n",
       " 'boring',\n",
       " 'this',\n",
       " 'as',\n",
       " 'and',\n",
       " 'and',\n",
       " 'br',\n",
       " 'villain',\n",
       " 'and',\n",
       " 'and',\n",
       " 'need',\n",
       " 'has',\n",
       " 'of',\n",
       " 'costumes',\n",
       " 'b',\n",
       " 'message',\n",
       " 'to',\n",
       " 'may',\n",
       " 'of',\n",
       " 'props',\n",
       " 'this',\n",
       " 'and',\n",
       " 'and',\n",
       " 'concept',\n",
       " 'issue',\n",
       " 'and',\n",
       " 'to',\n",
       " \"god's\",\n",
       " 'he',\n",
       " 'is',\n",
       " 'and',\n",
       " 'unfolds',\n",
       " 'movie',\n",
       " 'women',\n",
       " 'like',\n",
       " \"isn't\",\n",
       " 'surely',\n",
       " \"i'm\",\n",
       " 'and',\n",
       " 'to',\n",
       " 'toward',\n",
       " 'in',\n",
       " \"here's\",\n",
       " 'for',\n",
       " 'from',\n",
       " 'did',\n",
       " 'having',\n",
       " 'because',\n",
       " 'very',\n",
       " 'quality',\n",
       " 'it',\n",
       " 'is',\n",
       " 'and',\n",
       " 'and',\n",
       " 'really',\n",
       " 'book',\n",
       " 'is',\n",
       " 'both',\n",
       " 'too',\n",
       " 'worked',\n",
       " 'carl',\n",
       " 'of',\n",
       " 'and',\n",
       " 'br',\n",
       " 'of',\n",
       " 'reviewer',\n",
       " 'closer',\n",
       " 'figure',\n",
       " 'really',\n",
       " 'there',\n",
       " 'will',\n",
       " 'and',\n",
       " 'things',\n",
       " 'is',\n",
       " 'far',\n",
       " 'this',\n",
       " 'make',\n",
       " 'mistakes',\n",
       " 'and',\n",
       " 'was',\n",
       " \"couldn't\",\n",
       " 'of',\n",
       " 'few',\n",
       " 'br',\n",
       " 'of',\n",
       " 'you',\n",
       " 'to',\n",
       " \"don't\",\n",
       " 'female',\n",
       " 'than',\n",
       " 'place',\n",
       " 'she',\n",
       " 'to',\n",
       " 'was',\n",
       " 'between',\n",
       " 'that',\n",
       " 'nothing',\n",
       " 'and',\n",
       " 'movies',\n",
       " 'get',\n",
       " 'are',\n",
       " 'and',\n",
       " 'br',\n",
       " 'yes',\n",
       " 'female',\n",
       " 'just',\n",
       " 'its',\n",
       " 'because',\n",
       " 'many',\n",
       " 'br',\n",
       " 'of',\n",
       " 'overly',\n",
       " 'to',\n",
       " 'descent',\n",
       " 'people',\n",
       " 'time',\n",
       " 'very',\n",
       " 'bland']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id2word.get(i, '') for i in X_train[6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2569"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max review length\n",
    "len(max((X_train + X_test), key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#min review length\n",
    "len(min((X_train + X_test), key=len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model : RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/grace/workspace/keras/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=max_words))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/grace/workspace/keras/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epoches = 30\n",
    "validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', \\\n",
    "                                       patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
    "# X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
    "# history = model.fit(X_train2, y_train2,\\\n",
    "#                     validation_split=(X_valid, y_valid),\\\n",
    "#                    batch_size=batch_size, epochs=num_epoches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "20000/20000 [==============================] - 231s - loss: 0.5407 - acc: 0.7393 - val_loss: 0.3872 - val_acc: 0.8362\n",
      "Epoch 2/30\n",
      "20000/20000 [==============================] - 224s - loss: 0.3415 - acc: 0.8593 - val_loss: 0.3626 - val_acc: 0.8476\n",
      "Epoch 3/30\n",
      "20000/20000 [==============================] - 225s - loss: 0.2844 - acc: 0.8868 - val_loss: 0.3422 - val_acc: 0.8578\n",
      "Epoch 4/30\n",
      "20000/20000 [==============================] - 233s - loss: 0.2481 - acc: 0.9073 - val_loss: 0.3395 - val_acc: 0.8590\n",
      "Epoch 5/30\n",
      "20000/20000 [==============================] - 228s - loss: 0.2143 - acc: 0.9190 - val_loss: 0.3405 - val_acc: 0.8626\n",
      "Epoch 6/30\n",
      "20000/20000 [==============================] - 30381s - loss: 0.2005 - acc: 0.9267 - val_loss: 0.3651 - val_acc: 0.8476\n",
      "Epoch 7/30\n",
      "20000/20000 [==============================] - 223s - loss: 0.2064 - acc: 0.9251 - val_loss: 0.3598 - val_acc: 0.8540\n",
      "Epoch 8/30\n",
      "20000/20000 [==============================] - 223s - loss: 0.2022 - acc: 0.9203 - val_loss: 0.3896 - val_acc: 0.8606\n",
      "Epoch 9/30\n",
      "20000/20000 [==============================] - 224s - loss: 0.2301 - acc: 0.9018 - val_loss: 0.3887 - val_acc: 0.8452\n",
      "Epoch 10/30\n",
      "20000/20000 [==============================] - 224s - loss: 0.1661 - acc: 0.9384 - val_loss: 0.4145 - val_acc: 0.8464\n",
      "Epoch 11/30\n",
      "20000/20000 [==============================] - 220s - loss: 0.1495 - acc: 0.9446 - val_loss: 0.4201 - val_acc: 0.8442\n",
      "Epoch 12/30\n",
      "20000/20000 [==============================] - 227s - loss: 0.1112 - acc: 0.9607 - val_loss: 0.4757 - val_acc: 0.8566\n",
      "Epoch 13/30\n",
      "20000/20000 [==============================] - 237s - loss: 0.0937 - acc: 0.9688 - val_loss: 0.5574 - val_acc: 0.8336\n",
      "Epoch 14/30\n",
      "20000/20000 [==============================] - 230s - loss: 0.0988 - acc: 0.9653 - val_loss: 0.5253 - val_acc: 0.8508\n",
      "Epoch 15/30\n",
      "20000/20000 [==============================] - 230s - loss: 0.0823 - acc: 0.9731 - val_loss: 0.5461 - val_acc: 0.8524\n",
      "Epoch 16/30\n",
      "20000/20000 [==============================] - 241s - loss: 0.0847 - acc: 0.9710 - val_loss: 0.5694 - val_acc: 0.8474\n",
      "Epoch 17/30\n",
      "20000/20000 [==============================] - 240s - loss: 0.0560 - acc: 0.9832 - val_loss: 0.6783 - val_acc: 0.8454\n",
      "Epoch 18/30\n",
      "20000/20000 [==============================] - 343s - loss: 0.0500 - acc: 0.9860 - val_loss: 0.6067 - val_acc: 0.8242\n",
      "Epoch 19/30\n",
      "20000/20000 [==============================] - 361s - loss: 0.0444 - acc: 0.9874 - val_loss: 0.7424 - val_acc: 0.8524\n",
      "Epoch 20/30\n",
      "20000/20000 [==============================] - 361s - loss: 0.0412 - acc: 0.9883 - val_loss: 0.6811 - val_acc: 0.8384\n",
      "Epoch 21/30\n",
      "20000/20000 [==============================] - 361s - loss: 0.0920 - acc: 0.9687 - val_loss: 0.5617 - val_acc: 0.8406\n",
      "Epoch 22/30\n",
      "20000/20000 [==============================] - 362s - loss: 0.0524 - acc: 0.9843 - val_loss: 0.7160 - val_acc: 0.8370\n",
      "Epoch 23/30\n",
      "20000/20000 [==============================] - 509s - loss: 0.0344 - acc: 0.9908 - val_loss: 0.7620 - val_acc: 0.8414\n",
      "Epoch 24/30\n",
      "20000/20000 [==============================] - 34505s - loss: 0.0240 - acc: 0.9940 - val_loss: 0.8129 - val_acc: 0.8366\n",
      "Epoch 25/30\n",
      "20000/20000 [==============================] - 388s - loss: 0.0223 - acc: 0.9944 - val_loss: 0.8805 - val_acc: 0.8442\n",
      "Epoch 26/30\n",
      "20000/20000 [==============================] - 358s - loss: 0.0142 - acc: 0.9961 - val_loss: 0.8842 - val_acc: 0.8264\n",
      "Epoch 27/30\n",
      "20000/20000 [==============================] - 358s - loss: 0.0181 - acc: 0.9956 - val_loss: 0.9991 - val_acc: 0.8416\n",
      "Epoch 28/30\n",
      "20000/20000 [==============================] - 357s - loss: 0.0349 - acc: 0.9891 - val_loss: 0.8234 - val_acc: 0.7808\n",
      "Epoch 29/30\n",
      "20000/20000 [==============================] - 355s - loss: 0.0240 - acc: 0.9929 - val_loss: 0.9125 - val_acc: 0.8406\n",
      "Epoch 30/30\n",
      "20000/20000 [==============================] - 357s - loss: 0.0117 - acc: 0.9979 - val_loss: 1.0476 - val_acc: 0.8252\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\\\n",
    "                   batch_size=batch_size, epochs=num_epoches,\\\n",
    "                   verbose=1, validation_split=validation_split,\\\n",
    "                   callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 133s   \n",
      "\n",
      "\n",
      "test score :  1.0346745039898158\n",
      "test accuracy :  0.82944\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('\\n')\n",
    "print('test score : ', score[0])\n",
    "print('test accuracy : ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
