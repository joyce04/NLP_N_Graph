{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate testing dataset by cosine similarity \n",
    "- between corresponding parts (higher the better)\n",
    "- between 10,000 random parts (lower the better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://radimrehurek.com/topic_modeling_tutorial/2%20-%20Topic%20Modeling.html\n",
    "- http://www.creativmark.com/blog/similarity-measure-of-textual-documents_p12.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking if text is missing\n",
      "id       False\n",
      "title    False\n",
      "dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(45352, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retrieve table titles from csv\n",
    "data = pd.read_csv('titles.csv', delimiter='\\t', error_bad_lines=True, header=None)\n",
    "data.columns = ['id', 'title']\n",
    "data.title = data.title.str.strip()\n",
    "documents = data\n",
    "documents['title'].replace('', np.nan, inplace=True)\n",
    "documents = documents.astype(str)\n",
    "print('checking if text is missing')\n",
    "print(documents.isna().any())\n",
    "# documents.dropna(subset=['title'], inplace=True)\n",
    "documents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.parsing.preprocessing import strip_numeric\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "STOP_WORDS = list(gensim.parsing.preprocessing.STOPWORDS)\n",
    "STOP_WORDS.extend(['table', 'legend'])\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "#     deacc=True removes punctuations\n",
    "    for token in gensim.utils.simple_preprocess(text, deacc=True):\n",
    "        if token not in STOP_WORDS and len(token)>1:\n",
    "#             result.append(lemmatize_stemming(strip_numeric(token)))\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4105</td>\n",
       "      <td>[baselin, characterist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4106</td>\n",
       "      <td>[analysi, efficaci]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4107</td>\n",
       "      <td>[comparison, postop, carbohydr, antigen, level...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4108</td>\n",
       "      <td>[pattern, diseas, relaps]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4109</td>\n",
       "      <td>[grade, advers, event, gemcitabin, gemcitabin,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              title\n",
       "0  4105                            [baselin, characterist]\n",
       "1  4106                                [analysi, efficaci]\n",
       "2  4107  [comparison, postop, carbohydr, antigen, level...\n",
       "3  4108                          [pattern, diseas, relaps]\n",
       "4  4109  [grade, advers, event, gemcitabin, gemcitabin,..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#process the text, save the results as processed_docs\n",
    "processed_docs = pd.DataFrame()\n",
    "processed_docs = pd.concat([documents.id, documents.title.map(preprocess)], axis=1)\n",
    "processed_docs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_count = ignore all words and bigrams with total collected count lower than this value\n",
    "#threshold = represent a score threshold for forming the phrases(higher means fewer phrases)\n",
    "bigram = gensim.models.Phrases(processed_docs, min_count=1, threshold=1)\n",
    "trigram = gensim.models.Phrases(bigram[processed_docs], threshold=1)\n",
    "\n",
    "#sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "def make_bigram(text):\n",
    "    processed_text = [[word for word in simple_preprocess(str(doc)) if word not in STOP_WORDS] for doc in text]\n",
    "    return [bigram_mod[doc] for doc in processed_text]\n",
    "\n",
    "def make_trigram(text):\n",
    "    processed_text = [[word for word in simple_preprocess(str(doc)) if word not in STOP_WORDS] for doc in text]\n",
    "    return trigram_mod[[bigram_mod[doc] for doc in processed_text]]\n",
    "\n",
    "def explain_make_trigram(text):\n",
    "    conversion = {}\n",
    "    for doc in text:\n",
    "        pro_doc = simple_preprocess(str(doc))\n",
    "        if doc!= pro_doc:\n",
    "            print(doc)\n",
    "            print(pro_doc)\n",
    "            conversion[doc]=pro_doc\n",
    "    return conversion\n",
    "\n",
    "def n_gram_lemmatization(text, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    text_out = []\n",
    "    for sent in text:\n",
    "        doc = nlp(' '.join(sent))\n",
    "        text_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return text_out\n",
    "\n",
    "def explain_n_gram_lemmatization(text, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    conversions = {}\n",
    "    for sent in text:\n",
    "        doc = nlp(' '.join(sent))\n",
    "        for token in doc:\n",
    "            if len(token.lemma_) <4 and str(token)!=str(token.lemma_):\n",
    "                conversions[token] = token.lemma_\n",
    "#                 print('%s : %s' (token, token.lemma_))\n",
    "    return conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45352\n",
      "45352\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>bigram</th>\n",
       "      <th>trigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4105</td>\n",
       "      <td>[baselin, characterist]</td>\n",
       "      <td>[baselin, characterist]</td>\n",
       "      <td>[baselin, characterist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4106</td>\n",
       "      <td>[analysi, efficaci]</td>\n",
       "      <td>[analysi, efficaci]</td>\n",
       "      <td>[analysi, efficaci]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4107</td>\n",
       "      <td>[comparison, postop, carbohydr, antigen, level...</td>\n",
       "      <td>[comparison, postop, carbohydr, antigen, level...</td>\n",
       "      <td>[comparison, postop, carbohydr, antigen, level...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4108</td>\n",
       "      <td>[pattern, diseas, relaps]</td>\n",
       "      <td>[pattern, disea, relap]</td>\n",
       "      <td>[pattern, disea, relap]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4109</td>\n",
       "      <td>[grade, advers, event, gemcitabin, gemcitabin,...</td>\n",
       "      <td>[grade, adver, event, gemcitabin, gemcitabin, ...</td>\n",
       "      <td>[grade, adver, event, gemcitabin, gemcitabin, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4111</td>\n",
       "      <td>[baselin, characterist]</td>\n",
       "      <td>[baselin, characterist]</td>\n",
       "      <td>[baselin, characterist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4112</td>\n",
       "      <td>[treatment, zoledron, acid]</td>\n",
       "      <td>[treatment, zoledron, acid]</td>\n",
       "      <td>[treatment, zoledron, acid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4113</td>\n",
       "      <td>[treatment, docetaxel]</td>\n",
       "      <td>[treatment, docetaxel]</td>\n",
       "      <td>[treatment, docetaxel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4114</td>\n",
       "      <td>[treatment, relaps, discret, treat, clinician]</td>\n",
       "      <td>[treatment, relap, discret, treat, clinician]</td>\n",
       "      <td>[treatment, relap, discret, treat, clinician]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4115</td>\n",
       "      <td>[worst, advers, event, grade, report, entir, t...</td>\n",
       "      <td>[bad, adver, event, grade, report, entir, time...</td>\n",
       "      <td>[bad, adver, event, grade, report, entir, time...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              title  \\\n",
       "0  4105                            [baselin, characterist]   \n",
       "1  4106                                [analysi, efficaci]   \n",
       "2  4107  [comparison, postop, carbohydr, antigen, level...   \n",
       "3  4108                          [pattern, diseas, relaps]   \n",
       "4  4109  [grade, advers, event, gemcitabin, gemcitabin,...   \n",
       "5  4111                            [baselin, characterist]   \n",
       "6  4112                        [treatment, zoledron, acid]   \n",
       "7  4113                             [treatment, docetaxel]   \n",
       "8  4114     [treatment, relaps, discret, treat, clinician]   \n",
       "9  4115  [worst, advers, event, grade, report, entir, t...   \n",
       "\n",
       "                                              bigram  \\\n",
       "0                            [baselin, characterist]   \n",
       "1                                [analysi, efficaci]   \n",
       "2  [comparison, postop, carbohydr, antigen, level...   \n",
       "3                            [pattern, disea, relap]   \n",
       "4  [grade, adver, event, gemcitabin, gemcitabin, ...   \n",
       "5                            [baselin, characterist]   \n",
       "6                        [treatment, zoledron, acid]   \n",
       "7                             [treatment, docetaxel]   \n",
       "8      [treatment, relap, discret, treat, clinician]   \n",
       "9  [bad, adver, event, grade, report, entir, time...   \n",
       "\n",
       "                                             trigram  \n",
       "0                            [baselin, characterist]  \n",
       "1                                [analysi, efficaci]  \n",
       "2  [comparison, postop, carbohydr, antigen, level...  \n",
       "3                            [pattern, disea, relap]  \n",
       "4  [grade, adver, event, gemcitabin, gemcitabin, ...  \n",
       "5                            [baselin, characterist]  \n",
       "6                        [treatment, zoledron, acid]  \n",
       "7                             [treatment, docetaxel]  \n",
       "8      [treatment, relap, discret, treat, clinician]  \n",
       "9  [bad, adver, event, grade, report, entir, time...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_bigram = n_gram_lemmatization(make_bigram(processed_docs.title))\n",
    "processed_trigram = n_gram_lemmatization(make_trigram(processed_docs.title))\n",
    "print(str(len(processed_bigram)))\n",
    "print(str(len(processed_trigram)))\n",
    "processed_docs['bigram'] = processed_bigram\n",
    "processed_docs['trigram'] = processed_trigram\n",
    "processed_docs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_made_by = processed_trigram\n",
    "dictionary_made_by_str = 'trigram'\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(dictionary_made_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 227 (\"clinic\") appears 1 times.\n",
      "Word 237 (\"arteri\") appears 1 times.\n",
      "Word 238 (\"coronari\") appears 1 times.\n",
      "Word 269 (\"calcif\") appears 1 times.\n",
      "Word 270 (\"correl\") appears 1 times.\n",
      "Word 271 (\"score\") appears 1 times.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>bigram</th>\n",
       "      <th>trigram</th>\n",
       "      <th>bow_corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4105</td>\n",
       "      <td>[baselin, characterist]</td>\n",
       "      <td>[baselin, characterist]</td>\n",
       "      <td>[baselin, characterist]</td>\n",
       "      <td>[(0, 1), (1, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4106</td>\n",
       "      <td>[analysi, efficaci]</td>\n",
       "      <td>[analysi, efficaci]</td>\n",
       "      <td>[analysi, efficaci]</td>\n",
       "      <td>[(2, 1), (3, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4107</td>\n",
       "      <td>[comparison, postop, carbohydr, antigen, level...</td>\n",
       "      <td>[comparison, postop, carbohydr, antigen, level...</td>\n",
       "      <td>[comparison, postop, carbohydr, antigen, level...</td>\n",
       "      <td>[(4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4108</td>\n",
       "      <td>[pattern, diseas, relaps]</td>\n",
       "      <td>[pattern, disea, relap]</td>\n",
       "      <td>[pattern, disea, relap]</td>\n",
       "      <td>[(14, 1), (15, 1), (16, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4109</td>\n",
       "      <td>[grade, advers, event, gemcitabin, gemcitabin,...</td>\n",
       "      <td>[grade, adver, event, gemcitabin, gemcitabin, ...</td>\n",
       "      <td>[grade, adver, event, gemcitabin, gemcitabin, ...</td>\n",
       "      <td>[(17, 1), (18, 1), (19, 1), (20, 2), (21, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4111</td>\n",
       "      <td>[baselin, characterist]</td>\n",
       "      <td>[baselin, characterist]</td>\n",
       "      <td>[baselin, characterist]</td>\n",
       "      <td>[(0, 1), (1, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4112</td>\n",
       "      <td>[treatment, zoledron, acid]</td>\n",
       "      <td>[treatment, zoledron, acid]</td>\n",
       "      <td>[treatment, zoledron, acid]</td>\n",
       "      <td>[(22, 1), (23, 1), (24, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4113</td>\n",
       "      <td>[treatment, docetaxel]</td>\n",
       "      <td>[treatment, docetaxel]</td>\n",
       "      <td>[treatment, docetaxel]</td>\n",
       "      <td>[(23, 1), (25, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4114</td>\n",
       "      <td>[treatment, relaps, discret, treat, clinician]</td>\n",
       "      <td>[treatment, relap, discret, treat, clinician]</td>\n",
       "      <td>[treatment, relap, discret, treat, clinician]</td>\n",
       "      <td>[(16, 1), (23, 1), (26, 1), (27, 1), (28, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4115</td>\n",
       "      <td>[worst, advers, event, grade, report, entir, t...</td>\n",
       "      <td>[bad, adver, event, grade, report, entir, time...</td>\n",
       "      <td>[bad, adver, event, grade, report, entir, time...</td>\n",
       "      <td>[(13, 1), (17, 1), (19, 1), (21, 1), (29, 1), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              title  \\\n",
       "0  4105                            [baselin, characterist]   \n",
       "1  4106                                [analysi, efficaci]   \n",
       "2  4107  [comparison, postop, carbohydr, antigen, level...   \n",
       "3  4108                          [pattern, diseas, relaps]   \n",
       "4  4109  [grade, advers, event, gemcitabin, gemcitabin,...   \n",
       "5  4111                            [baselin, characterist]   \n",
       "6  4112                        [treatment, zoledron, acid]   \n",
       "7  4113                             [treatment, docetaxel]   \n",
       "8  4114     [treatment, relaps, discret, treat, clinician]   \n",
       "9  4115  [worst, advers, event, grade, report, entir, t...   \n",
       "\n",
       "                                              bigram  \\\n",
       "0                            [baselin, characterist]   \n",
       "1                                [analysi, efficaci]   \n",
       "2  [comparison, postop, carbohydr, antigen, level...   \n",
       "3                            [pattern, disea, relap]   \n",
       "4  [grade, adver, event, gemcitabin, gemcitabin, ...   \n",
       "5                            [baselin, characterist]   \n",
       "6                        [treatment, zoledron, acid]   \n",
       "7                             [treatment, docetaxel]   \n",
       "8      [treatment, relap, discret, treat, clinician]   \n",
       "9  [bad, adver, event, grade, report, entir, time...   \n",
       "\n",
       "                                             trigram  \\\n",
       "0                            [baselin, characterist]   \n",
       "1                                [analysi, efficaci]   \n",
       "2  [comparison, postop, carbohydr, antigen, level...   \n",
       "3                            [pattern, disea, relap]   \n",
       "4  [grade, adver, event, gemcitabin, gemcitabin, ...   \n",
       "5                            [baselin, characterist]   \n",
       "6                        [treatment, zoledron, acid]   \n",
       "7                             [treatment, docetaxel]   \n",
       "8      [treatment, relap, discret, treat, clinician]   \n",
       "9  [bad, adver, event, grade, report, entir, time...   \n",
       "\n",
       "                                          bow_corpus  \n",
       "0                                   [(0, 1), (1, 1)]  \n",
       "1                                   [(2, 1), (3, 1)]  \n",
       "2  [(4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1...  \n",
       "3                        [(14, 1), (15, 1), (16, 1)]  \n",
       "4      [(17, 1), (18, 1), (19, 1), (20, 2), (21, 1)]  \n",
       "5                                   [(0, 1), (1, 1)]  \n",
       "6                        [(22, 1), (23, 1), (24, 1)]  \n",
       "7                                 [(23, 1), (25, 1)]  \n",
       "8      [(16, 1), (23, 1), (26, 1), (27, 1), (28, 1)]  \n",
       "9  [(13, 1), (17, 1), (19, 1), (21, 1), (29, 1), ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize\n",
    "# Bag-of-words representation of the documents\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in dictionary_made_by]\n",
    "\n",
    "bow_doc_100 = bow_corpus[100]\n",
    "for i in range(len(bow_doc_100)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} times.\".format(bow_doc_100[i][0],\n",
    "                                                     dictionary[bow_doc_100[i][0]],\n",
    "                                                     bow_doc_100[i][1]))\n",
    "\n",
    "processed_docs['bow_corpus'] = bow_corpus\n",
    "processed_docs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  [('event', 0.0866143533664295),\n",
      "   ('treatment', 0.07293358651140446),\n",
      "   ('popul', 0.04930109125849329),\n",
      "   ('adver', 0.04927821372194642),\n",
      "   ('patient', 0.029008716341424354),\n",
      "   ('treat', 0.027018370661847133),\n",
      "   ('outcom', 0.02482212715334813),\n",
      "   ('group', 0.02058978289217817),\n",
      "   ('primari', 0.02033812999016266),\n",
      "   ('characterist', 0.01885109011461646)]),\n",
      " (1,\n",
      "  [('coronari', 0.04859830492688833),\n",
      "   ('arteri', 0.03412498835801434),\n",
      "   ('leav', 0.03332401974480768),\n",
      "   ('heart', 0.03310049362019186),\n",
      "   ('ventricular', 0.031573065101983794),\n",
      "   ('myocardi', 0.025016298779919902),\n",
      "   ('infarct', 0.02224084939927354),\n",
      "   ('pressur', 0.020024215330166715),\n",
      "   ('blood', 0.018198751979137562),\n",
      "   ('end', 0.015181149296824067)]),\n",
      " (2,\n",
      "  [('year', 0.05378393351800554),\n",
      "   ('age', 0.04660387811634349),\n",
      "   ('relat', 0.026371191135734072),\n",
      "   ('cancer', 0.02047645429362881),\n",
      "   ('number', 0.0188808864265928),\n",
      "   ('incid', 0.018459833795013852),\n",
      "   ('woman', 0.01637673130193906),\n",
      "   ('rat', 0.015778393351800556),\n",
      "   ('estim', 0.015534626038781163),\n",
      "   ('child', 0.01378393351800554)]),\n",
      " (3,\n",
      "  [('analysi', 0.053262205922190504),\n",
      "   ('risk', 0.04701077330221509),\n",
      "   ('mortal', 0.03559148971639334),\n",
      "   ('multivari', 0.03284085936360416),\n",
      "   ('death', 0.032465773406405635),\n",
      "   ('factor', 0.03223655421033987),\n",
      "   ('model', 0.029902686032215717),\n",
      "   ('ratio', 0.029735981162349705),\n",
      "   ('associ', 0.028423180312154867),\n",
      "   ('regress', 0.028048094354956345)]),\n",
      " (4,\n",
      "  [('characterist', 0.13504203775466267),\n",
      "   ('baselin', 0.08054025879846806),\n",
      "   ('patient', 0.06841616244022934),\n",
      "   ('studi', 0.04511976794252952),\n",
      "   ('group', 0.036689555147642036),\n",
      "   ('clinic', 0.029732363405624674),\n",
      "   ('accord', 0.024044235955310807),\n",
      "   ('follow', 0.019942438869626305),\n",
      "   ('outcom', 0.019466539760237496),\n",
      "   ('control', 0.016520497654497247)]),\n",
      " (5,\n",
      "  [('characterist', 0.0425833600146366),\n",
      "   ('patient', 0.04185152998216164),\n",
      "   ('clinic', 0.03977038832731098),\n",
      "   ('baselin', 0.03636280473859946),\n",
      "   ('disea', 0.02561405113662352),\n",
      "   ('demograph', 0.02318986415405022),\n",
      "   ('studi', 0.017380963271280244),\n",
      "   ('diabet', 0.014956776288706947),\n",
      "   ('cohort', 0.014522252206924942),\n",
      "   ('control', 0.01328728902712345)]),\n",
      " (6,\n",
      "  [('patient', 0.03716492503407542),\n",
      "   ('hospit', 0.023875511131303952),\n",
      "   ('test', 0.021353930031803726),\n",
      "   ('result', 0.018128123580190822),\n",
      "   ('paramet', 0.017469332121762837),\n",
      "   ('high', 0.01562925942753294),\n",
      "   ('characterist', 0.015152203543843707),\n",
      "   ('day', 0.013539300318037255),\n",
      "   ('low', 0.01283507496592458),\n",
      "   ('activ', 0.012426169922762381)]),\n",
      " (7,\n",
      "  [('patient', 0.062181400688863374),\n",
      "   ('baselin', 0.04424799081515499),\n",
      "   ('characterist', 0.04289322617680827),\n",
      "   ('datum', 0.029690011481056256),\n",
      "   ('procedur', 0.021148105625717565),\n",
      "   ('angiograph', 0.019035591274397246),\n",
      "   ('group', 0.018553386911595866),\n",
      "   ('clinic', 0.01701492537313433),\n",
      "   ('score', 0.01667049368541906),\n",
      "   ('therapi', 0.015958668197474168)])]\n"
     ]
    }
   ],
   "source": [
    "# from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "# dir_to_check = Path(directory+'/data/')\n",
    "# if not dir_to_check.is_dir():\n",
    "#     os.makedirs(directory+'/data/')\n",
    "mallet_path = './mallet-2.0.8/bin/mallet'\n",
    "\n",
    "directory ='./cosine_similarity/'\n",
    "optimal_topic_num = 8\n",
    "lda_mallet = gensim.models.wrappers.LdaMallet(mallet_path=mallet_path, \\\n",
    "                                              corpus=bow_corpus, \\\n",
    "                                              num_topics=optimal_topic_num, \\\n",
    "                                              id2word=dictionary,\\\n",
    "                                            iterations=100,\\\n",
    "                                             prefix=directory)\n",
    "\n",
    "#show topics\n",
    "pprint(lda_mallet.show_topics(formatted=False))\n",
    "# lda_mallet.load_word_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = lda_mallet.show_topics(formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def format_topics_sentences(model, \\\n",
    "                            model_type='mallet', \\\n",
    "                            corpus=processed_docs, \\\n",
    "                            texts=dictionary_made_by):\n",
    "    sent_topic_df = pd.DataFrame()\n",
    "    if model_type=='tfidf':\n",
    "        target_corpus = corpus.tfidf_corpus\n",
    "    else:\n",
    "        target_corpus = corpus.bow_corpus\n",
    "    \n",
    "    for i, row in enumerate(model[target_corpus]):\n",
    "        origin_info = processed_docs.iloc[i]\n",
    "        text_vec = texts[i]\n",
    "        #get main topic in each document\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j==0: #dominant topic\n",
    "                wp = model.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "#                 print(pd.Series([origin_info.id,\\\n",
    "#                                 int(topic_num), \\\n",
    "#                                 round(prop_topic, 4), \\\n",
    "#                                 topic_keywords, \\\n",
    "#                                origin_info.title_y, \\\n",
    "#                                text_vec]))\n",
    "                sent_topic_df = sent_topic_df.append(pd.Series([origin_info.id,\\\n",
    "                                                                int(topic_num), \\\n",
    "                                                                round(prop_topic, 4), \\\n",
    "                                                                topic_keywords, \\\n",
    "                                                               origin_info.title_y, \\\n",
    "                                                               text_vec]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topic_df.columns = ['id', 'Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords', 'Origin_Text', 'Text_Vec']\n",
    "\n",
    "    return (sent_topic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = processed_docs.merge(documents, on='id')\n",
    "\n",
    "df_topic_sents_keywords_mallet = format_topics_sentences(model=lda_mallet, \\\n",
    "                                                  corpus=processed_docs, \\\n",
    "                                                  texts=dictionary_made_by, \\\n",
    "                                                 model_type='mallet')\n",
    "df_topic_sents_keywords_mallet.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_bow = processed_docs[['id', 'bow_corpus']]\n",
    "df_topic_sents_keywords_mallet = df_topic_sents_keywords_mallet.merge(pro_bow, on='id')\n",
    "df_topic_sents_keywords_mallet.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intra_inter(model, test_docs, num_pairs=10000):\n",
    "    for indx, grp in df_topic_sents_keywords_mallet.groupby('Dominant_Topic'):\n",
    "        # split each test document into two halves and compute topics for each half\n",
    "        grp_size = len(grp)\n",
    "        half_size = int(grp_size/2)\n",
    "        part1 = grp.Text_Vec[:half_size]\n",
    "        part2 = grp.Text_Vec[half_size:]\n",
    "    \n",
    "        # print computed similarities (uses cossim)\n",
    "        print(\"average cosine similarity between corresponding parts (higher is better):\")\n",
    "        print(np.mean([gensim.matutils.cossim(p1, p2) for p1, p2 in zip(part1, part2)]))\n",
    "\n",
    "#     random_pairs = np.random.randint(0, len(test_docs), size=(num_pairs, 2))\n",
    "#     print(\"average cosine similarity between 10,000 random parts (lower is better):\")    \n",
    "#     print(np.mean([gensim.matutils.cossim(part1[i[0]], part2[i[1]]) for i in random_pairs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LDA results:\")\n",
    "intra_inter(lda_mallet, bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = gensim.similarities.MatrixSimilarity(lda_mallet[bow_corpus])\n",
    "index.save(\"simIndex.index\")\n",
    "\n",
    "vec_bow = dictionary.doc2bow(processed_docs)\n",
    "vec_lda = lda_mallet[vec_bow]\n",
    "\n",
    "sims = index[vec_lda]\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
