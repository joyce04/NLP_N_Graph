{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cluster a set of documents using Python\n",
    "\n",
    "1. tokenizing\n",
    "2. stemming (*based on stemming lib, results change)- reduce a word to its stem or root form\n",
    "3. calculate cosine distance between each document = measure of similarity\n",
    "4. cluster documents using the k-means algorithm\n",
    "5. using multidimensional scaling to reduce dimensionality within the corpus\n",
    "6. conduct a hierarchical clustering on the corpus using Ward clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References :\n",
    "- https://datascienceschool.net/view-notebook/3e7aadbf88ed4f0d87a76f9ddc925d69/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "import mpld3\n",
    "import psycopg2\n",
    "# import db_conn\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = get_connection()\n",
    "\n",
    "def get_article_tables(is_file):\n",
    "    if is_file:\n",
    "        return pd.read_csv('../data/titles_condition_by_t.tsv', sep='\\t', header=None)\n",
    "#         return pd.read_csv('../topic_modeling/best_files/dic_unigram_size_6000/mallet_top_sen.tsv', sep='\\t')\n",
    "    else:\n",
    "        curs = conn.cursor()\n",
    "\n",
    "        select_sql = \"\"\"SELECT id, table_title, strip_tags(CONTENT) as content FROM article_tables order by id\"\"\" # limit 10000\n",
    "        curs.execute(select_sql)\n",
    "        return curs.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_article_tables(True)\n",
    "# train_data = train_data[['id', 'Origin_Text']]\n",
    "train_data.columns=['id', 'title']\n",
    "# clean_content = [x['content'].lower() for x in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4106</td>\n",
       "      <td>Analysis of efficacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4107</td>\n",
       "      <td>Comparisons of postoperative CA19-9 levels on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4108</td>\n",
       "      <td>Pattern of disease relapse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4109</td>\n",
       "      <td>Grade 1–5 adverse events with gemcitabine alon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4112</td>\n",
       "      <td>Treatment with zoledronic acid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              title\n",
       "0  4106                               Analysis of efficacy\n",
       "1  4107  Comparisons of postoperative CA19-9 levels on ...\n",
       "2  4108                         Pattern of disease relapse\n",
       "3  4109  Grade 1–5 adverse events with gemcitabine alon...\n",
       "4  4112                     Treatment with zoledronic acid"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id       False\n",
      "title    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "train_data.title = train_data.title.str.strip()\n",
    "train_data['title'].replace('', np.nan, inplace=True)\n",
    "print(train_data.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, title]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id       False\n",
      "title    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "train_data.loc[train_data.title.isna()]\n",
    "train_data.dropna(subset=['title'], inplace=True)\n",
    "print(train_data.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep = {'nbsp':'', 'table':'', 'legend':'', 'mg/dl':'', 'g/l':'', 'yrs':'year', '\\n':' ', ';':'', 'kg/m2':'', 'n=':''}\n",
    "rep = {'nbsp':'', 'table':'', 'legend':'', 'yrs':'year', '\\n':' '}\n",
    "# clean_content = [pattern.sub(lambda m: rep[re.escape(m.group(0))], x['content']) for x in train_data]\n",
    "rep = dict((re.escape(k), v) for k, v in rep.items())\n",
    "pattern = re.compile(\"|\".join(rep.keys()))\n",
    "train_data.title = [pattern.sub(lambda m: rep[re.escape(m.group(0))], str(x)) for x in train_data.title]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 Analysis of efficacy\n",
       "1    Comparisons of postoperative CA19-9 levels on ...\n",
       "2                           Pattern of disease relapse\n",
       "3    Grade 1–5 adverse events with gemcitabine alon...\n",
       "4                       Treatment with zoledronic acid\n",
       "5                             Treatment with docetaxel\n",
       "6    Treatments ever used at relapse, at the discre...\n",
       "7    Worst adverse event  (grade)  reported over en...\n",
       "8    Chemotherapy delivery and trial drug discontin...\n",
       "9                                       Adverse events\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.title[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.parsing.preprocessing import strip_numeric\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 8] nodename\n",
      "[nltk_data]     nor servname provided, or not known>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(2018)\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords\n",
    "stemmer = SnowballStemmer('english')\n",
    "STOP_WORDS = list(gensim.parsing.preprocessing.STOPWORDS)\n",
    "STOP_WORDS.extend(['table', 'legend'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming\n",
    "# -porter stemmer\n",
    "# -lancaster stemmer\n",
    "# -snowball stemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "#     deacc=True removes punctuations\n",
    "    for token in gensim.utils.simple_preprocess(text, deacc=True):\n",
    "        if token not in STOP_WORDS and len(token)>1:\n",
    "#             result.append(lemmatize_stemming(strip_numeric(token)))\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n",
    "\n",
    "def preprocess_token_only(text):\n",
    "    result = []\n",
    "#     deacc=True removes punctuations\n",
    "    for token in gensim.utils.simple_preprocess(text, deacc=True):\n",
    "        if token not in STOP_WORDS and len(token)>1:\n",
    "#             result.append(lemmatize_stemming(strip_numeric(token)))\n",
    "            result.append(token)\n",
    "    return result\n",
    "\n",
    "stemmer = LancasterStemmer()\n",
    "#tokenizing\n",
    "def tokenize_and_stem(text):\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    #filter tokens not containing letters\n",
    "    filtered = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token) and len(token)>2:\n",
    "            filtered.append(token)\n",
    "#     stems = [stemmer.stem(t, pos='v') for t in filtered]\n",
    "    stems = [stemmer.stem(t) for t in filtered]\n",
    "    return stems\n",
    "\n",
    "def tokenize_only(text):\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token) and len(token)>2:\n",
    "            filtered.append(token)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vocab_stemmed = []\n",
    "total_vocab_tokenized = []\n",
    "\n",
    "for i in train_data.title.tolist():\n",
    "    all_stemmed = preprocess(i)\n",
    "    total_vocab_stemmed.extend(all_stemmed)\n",
    "    \n",
    "    all_tokenized = preprocess_token_only(i)\n",
    "    total_vocab_tokenized.extend(all_tokenized)\n",
    "\n",
    "processed_docs = pd.DataFrame()\n",
    "processed_docs = pd.concat([train_data.id, train_data.title.map(preprocess)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4106</td>\n",
       "      <td>[analys, eff]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4107</td>\n",
       "      <td>[comparison, postop, ca, level, surv, espac, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4108</td>\n",
       "      <td>[pattern, diseas, relaps]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4109</td>\n",
       "      <td>[grad, advers, ev, gemcitabin, gemcitabin, plu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4112</td>\n",
       "      <td>[tre, zoledron, acid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4113</td>\n",
       "      <td>[tre, docetaxel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4114</td>\n",
       "      <td>[tre, relaps, discret, tre, clin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4115</td>\n",
       "      <td>[worst, advers, ev, grad, report, entir, tim, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4117</td>\n",
       "      <td>[chemotherapy, delivery, tri, drug, discontinu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4118</td>\n",
       "      <td>[advers, ev]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              title\n",
       "0  4106                                      [analys, eff]\n",
       "1  4107  [comparison, postop, ca, level, surv, espac, c...\n",
       "2  4108                          [pattern, diseas, relaps]\n",
       "3  4109  [grad, advers, ev, gemcitabin, gemcitabin, plu...\n",
       "4  4112                              [tre, zoledron, acid]\n",
       "5  4113                                   [tre, docetaxel]\n",
       "6  4114                  [tre, relaps, discret, tre, clin]\n",
       "7  4115  [worst, advers, ev, grad, report, entir, tim, ...\n",
       "8  4117    [chemotherapy, delivery, tri, drug, discontinu]\n",
       "9  4118                                       [advers, ev]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>analys</th>\n",
       "      <td>analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eff</th>\n",
       "      <td>efficacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comparison</th>\n",
       "      <td>comparisons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postop</th>\n",
       "      <td>postoperative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    words\n",
       "analys           analysis\n",
       "eff              efficacy\n",
       "comparison    comparisons\n",
       "postop      postoperative\n",
       "ca                     ca"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe with stemmed vocab and tokenized words (link)\n",
    "vocab_frame = pd.DataFrame({'words':total_vocab_tokenized}, index=total_vocab_stemmed)\n",
    "vocab_frame.drop_duplicates(inplace=True)\n",
    "vocab_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf and document similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.51 s, sys: 101 ms, total: 9.61 s\n",
      "Wall time: 9.64 s\n",
      "(27960, 147)\n"
     ]
    }
   ],
   "source": [
    "#frequency-inverse document frequencey(tf-idf) vectorize parameters and convert the document list into tf-idf matrix\n",
    "# 1. count word occurrences by document\n",
    "# 2. transform into a document-term matrix = term frequency matrix\n",
    "\n",
    "#max_df = max frequency within the documents\n",
    "#min_idf = if 5, the term would have to be in at least 5 of the documents to be considered, 0.2 = 20% of documents\n",
    "#ngram_ranges\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, \n",
    "                                   max_features=10000, \n",
    "                                   min_df=0.01, \n",
    "                                   stop_words='english', \n",
    "                                   use_idf=True, \n",
    "                                   lowercase=True, \n",
    "                                   tokenizer=preprocess)\n",
    "#                                    tokenizer=preprocess, ngram_range=(1,2))\n",
    "\n",
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(train_data.title)\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accord',\n",
       " 'act',\n",
       " 'acut',\n",
       " 'adjust',\n",
       " 'advers',\n",
       " 'ag',\n",
       " 'analys',\n",
       " 'angiograph',\n",
       " 'artery',\n",
       " 'assess']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dist = cosine similarity of each document\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "         8.53883514e-01,  1.00000000e+00,  1.00000000e+00],\n",
       "       [ 1.00000000e+00, -2.22044605e-16,  1.00000000e+00, ...,\n",
       "         5.88511646e-01,  1.00000000e+00,  1.00000000e+00],\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  0.00000000e+00, ...,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
       "       ...,\n",
       "       [ 8.53883514e-01,  5.88511646e-01,  1.00000000e+00, ...,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "         1.00000000e+00, -2.22044605e-16,  1.00000000e+00],\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "         1.00000000e+00,  1.00000000e+00, -2.22044605e-16]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HashingVectorizer, CountVectorizer\n",
    "\n",
    "- 문서 집합에서 단어 토큰을 생성하고 각 단어의 수를 세어 BOW 인코딩한 벡터를 만든다.\n",
    "- HashingVectorizer를 사용하면 해시 함수를 사용하여 단어에 대한 인덱스 번호를 생성하기 때문에 메모리 및 실행 시간을 줄일 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accord': 0,\n",
       " 'act': 1,\n",
       " 'acut': 2,\n",
       " 'adjust': 3,\n",
       " 'advers': 4,\n",
       " 'ag': 5,\n",
       " 'analys': 6,\n",
       " 'angiograph': 7,\n",
       " 'artery': 8,\n",
       " 'assess': 9,\n",
       " 'assocy': 10,\n",
       " 'bas': 11,\n",
       " 'blood': 12,\n",
       " 'cardiac': 13,\n",
       " 'cardiovascul': 14,\n",
       " 'cas': 15,\n",
       " 'categ': 16,\n",
       " 'caus': 17,\n",
       " 'chang': 18,\n",
       " 'childr': 19,\n",
       " 'class': 20,\n",
       " 'clin': 21,\n",
       " 'cohort': 22,\n",
       " 'combin': 23,\n",
       " 'comp': 24,\n",
       " 'comparison': 25,\n",
       " 'comply': 26,\n",
       " 'cont': 27,\n",
       " 'control': 28,\n",
       " 'coron': 29,\n",
       " 'correl': 30,\n",
       " 'country': 31,\n",
       " 'cox': 32,\n",
       " 'dat': 33,\n",
       " 'day': 34,\n",
       " 'dea': 35,\n",
       " 'death': 36,\n",
       " 'diagnos': 37,\n",
       " 'diff': 38,\n",
       " 'diseas': 39,\n",
       " 'distribut': 40,\n",
       " 'dos': 41,\n",
       " 'drug': 42,\n",
       " 'eff': 43,\n",
       " 'effect': 44,\n",
       " 'end': 45,\n",
       " 'endpoint': 46,\n",
       " 'estim': 47,\n",
       " 'ev': 48,\n",
       " 'exerc': 49,\n",
       " 'fact': 50,\n",
       " 'fail': 51,\n",
       " 'flow': 52,\n",
       " 'follow': 53,\n",
       " 'frequ': 54,\n",
       " 'funct': 55,\n",
       " 'gen': 56,\n",
       " 'group': 57,\n",
       " 'hazard': 58,\n",
       " 'heal': 59,\n",
       " 'heart': 60,\n",
       " 'hemodynam': 61,\n",
       " 'high': 62,\n",
       " 'hospit': 63,\n",
       " 'incid': 64,\n",
       " 'ind': 65,\n",
       " 'independ': 66,\n",
       " 'index': 67,\n",
       " 'individ': 68,\n",
       " 'infarct': 69,\n",
       " 'infect': 70,\n",
       " 'interv': 71,\n",
       " 'leav': 72,\n",
       " 'level': 73,\n",
       " 'log': 74,\n",
       " 'maj': 75,\n",
       " 'mean': 76,\n",
       " 'meas': 77,\n",
       " 'med': 78,\n",
       " 'model': 79,\n",
       " 'mon': 80,\n",
       " 'month': 81,\n",
       " 'mort': 82,\n",
       " 'mult': 83,\n",
       " 'multivary': 84,\n",
       " 'myocard': 85,\n",
       " 'non': 86,\n",
       " 'numb': 87,\n",
       " 'od': 88,\n",
       " 'op': 89,\n",
       " 'outcom': 90,\n",
       " 'overal': 91,\n",
       " 'paramet': 92,\n",
       " 'particip': 93,\n",
       " 'paty': 94,\n",
       " 'period': 95,\n",
       " 'point': 96,\n",
       " 'pop': 97,\n",
       " 'post': 98,\n",
       " 'predict': 99,\n",
       " 'pres': 100,\n",
       " 'press': 101,\n",
       " 'prev': 102,\n",
       " 'prim': 103,\n",
       " 'proc': 104,\n",
       " 'proport': 105,\n",
       " 'random': 106,\n",
       " 'rat': 107,\n",
       " 'ratio': 108,\n",
       " 'reg': 109,\n",
       " 'regress': 110,\n",
       " 'rel': 111,\n",
       " 'report': 112,\n",
       " 'respons': 113,\n",
       " 'result': 114,\n",
       " 'risk': 115,\n",
       " 'saf': 116,\n",
       " 'scor': 117,\n",
       " 'second': 118,\n",
       " 'select': 119,\n",
       " 'sensit': 120,\n",
       " 'sev': 121,\n",
       " 'sex': 122,\n",
       " 'sign': 123,\n",
       " 'spec': 124,\n",
       " 'stat': 125,\n",
       " 'stratify': 126,\n",
       " 'stroke': 127,\n",
       " 'study': 128,\n",
       " 'subgroup': 129,\n",
       " 'subject': 130,\n",
       " 'sum': 131,\n",
       " 'surv': 132,\n",
       " 'test': 133,\n",
       " 'therapy': 134,\n",
       " 'tim': 135,\n",
       " 'tot': 136,\n",
       " 'tre': 137,\n",
       " 'tri': 138,\n",
       " 'typ': 139,\n",
       " 'valu': 140,\n",
       " 'vary': 141,\n",
       " 'ventricul': 142,\n",
       " 'vers': 143,\n",
       " 'week': 144,\n",
       " 'wom': 145,\n",
       " 'year': 146}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "vect = CountVectorizer(max_df=0.8, \\\n",
    "                       min_df=0.01, \\\n",
    "                       max_features=10000,\\\n",
    "                       lowercase=True,\\\n",
    "                       tokenizer=preprocess,\\\n",
    "                       stop_words='english')\n",
    "# vect = HashingVectorizer(n_features=10000,\\\n",
    "#                        lowercase=True,\\\n",
    "#                        tokenizer=preprocess,\\\n",
    "#                        stop_words='english')\n",
    "\n",
    "# vect = CountVectorizer(max_df=0.8, min_df=0.02, ngram_range=(2,2))\n",
    "count_matrix = vect.fit_transform(train_data.title)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-means- predetermined number of clusters\n",
    "nums =[8]\n",
    "from sklearn.cluster import KMeans\n",
    "from __future__ import print_function\n",
    "\n",
    "def run_kmeans(vect):\n",
    "    for num in nums:\n",
    "        print('cluster : %s' % str(num))\n",
    "        num_clusters = num\n",
    "        km = KMeans(n_clusters=num_clusters,\\\n",
    "                    random_state=0,\\\n",
    "                    algorithm='auto',\\\n",
    "                    max_iter=20000)\n",
    "        %time km.fit(vect)\n",
    "        clusters = km.labels_.tolist()\n",
    "\n",
    "        documents = {'id':[x for x in processed_docs.id],\n",
    "                    'content': train_data.title.tolist(),\n",
    "                     'title': processed_docs.title.tolist(),\n",
    "                    'cluster':clusters}\n",
    "\n",
    "        clu_docu = pd.DataFrame(documents, index=[clusters], columns=['id','content','title','cluster'])\n",
    "\n",
    "        print(clu_docu['cluster'].value_counts())\n",
    "\n",
    "        #top words nearest to the cluster centroid\n",
    "        print('Top terms per clusters')\n",
    "        print()\n",
    "        order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "        for i in range(num_clusters):\n",
    "            print('Cluster %d words:' % i, end='')\n",
    "\n",
    "            for ind in order_centroids[i, :]:\n",
    "                print('%s' % vocab_frame.loc[terms[ind].split(' ')].values.tolist()[0][0], end=',')\n",
    "            print()\n",
    "\n",
    "            print(\"Cluster %d titles:\" % i, end='')\n",
    "            adver_contents = [x for x in clu_docu.loc[i]['content'].tolist() if x.lower().find('advers')>=0]\n",
    "            print('count of adverse included in content %s' % str(len(adver_contents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster : 8\n",
      "CPU times: user 18.2 s, sys: 95.9 ms, total: 18.3 s\n",
      "Wall time: 18.4 s\n",
      "3    14692\n",
      "6     2774\n",
      "7     2579\n",
      "2     2296\n",
      "1     2074\n",
      "5     1483\n",
      "0     1068\n",
      "4      994\n",
      "Name: cluster, dtype: int64\n",
      "Top terms per clusters\n",
      "\n",
      "Cluster 0 words:data,patients,clinician,hemodynamic,angiographic,procedures,groups,follow,summary,study,coronial,exercise,comparisons,according,outcomes,cardiac,operation,analysis,treatment,flow,control,basic,randomised,function,population,subjects,infarction,year,trials,mean,test,regions,mortality,artery,measures,time,ventricular,hospitalization,individual,related,comparative,heart,disease,children,months,weeks,post,genes,model,myocardial,change,states,month,different,days,left,events,number,cohorts,therapy,presenting,risk,safety,case,blood,correlates,stratified,intervals,complications,country,pressure,assessed,severely,index,estimated,versus,variable,dose,period,effectiveness,health,medication,value,diagnosed,factors,association,results,death,end,proportional,survival,participants,age,distribution,type,india,significantly,levels,response,major,acute,infection,rate,total,failure,non,women,drug,parameters,cause,score,categories,deaths,overall,efficacy,specific,sensitivity,class,subgroups,cox,reported,cardiovascular,prevalences,incidence,points,primary,predicted,high,logistic,combined,multivariate,hazards,sex,regression,concentrations,frequencies,stroke,adjusted,second,independent,odds,selective,ratio,multivariable,adverse,endpoints,activation,\n",
      "Cluster 0 titles:count of adverse included in content 0\n",
      "Cluster 1 words:outcomes,clinician,second,primary,treatment,patients,days,hospitalization,year,months,groups,according,follow,procedures,study,measures,safety,month,association,randomised,efficacy,effectiveness,population,related,predicted,analysis,angiographic,stratified,comparisons,women,events,states,intervals,risk,weeks,versus,function,health,cohorts,comparative,score,variable,adverse,adjusted,post,trials,different,time,cardiovascular,operation,summary,therapy,type,complications,subgroups,age,rate,control,major,acute,presenting,model,children,estimated,participants,assessed,drug,categories,period,incidence,change,factors,survival,levels,mortality,basic,mean,medication,non,ratio,case,disease,independent,individual,cardiac,regions,high,reported,specific,number,selective,severely,coronial,india,overall,results,infection,dose,hazards,concentrations,failure,multivariate,total,left,index,distribution,correlates,proportional,stroke,death,class,combined,end,infarction,artery,points,cause,myocardial,frequencies,activation,response,heart,ventricular,multivariable,test,sex,sensitivity,diagnosed,subjects,regression,value,cox,endpoints,significantly,parameters,odds,hemodynamic,country,prevalences,logistic,flow,genes,exercise,data,blood,pressure,deaths,\n",
      "Cluster 1 titles:count of adverse included in content 38\n",
      "Cluster 2 words:analysis,regression,multivariate,predicted,logistic,cox,model,variable,factors,multivariable,mortality,risk,patients,association,coronial,survival,death,subgroups,hazards,angiographic,proportional,events,independent,sensitivity,treatment,related,cardiac,clinician,results,study,effectiveness,year,cause,cardiovascular,days,disease,population,significantly,artery,hospitalization,states,outcomes,primary,adjusted,efficacy,follow,trials,parameters,heart,score,time,change,value,endpoints,overall,failure,presenting,groups,rate,post,measures,index,correlates,control,stroke,according,test,concentrations,levels,ratio,cohorts,months,function,myocardial,versus,basic,points,summary,infarction,intervals,major,selective,case,left,acute,different,randomised,second,total,response,blood,incidence,weeks,ventricular,estimated,end,stratified,flow,age,combined,activation,participants,month,regions,subjects,assessed,severely,number,pressure,women,comparative,non,specific,individual,children,procedures,high,therapy,comparisons,type,medication,operation,diagnosed,reported,odds,deaths,india,mean,exercise,dose,complications,health,hemodynamic,class,infection,safety,genes,period,prevalences,categories,adverse,sex,frequencies,country,data,distribution,drug,\n",
      "Cluster 2 titles:count of adverse included in content 10\n",
      "Cluster 3 words:risk,treatment,effectiveness,study,groups,association,related,variable,predicted,clinician,parameters,measures,mortality,change,factors,score,comparisons,ratio,according,disease,hemodynamic,death,coronial,response,time,cause,model,intervals,function,different,medication,states,days,value,mean,follow,concentrations,prevalences,incidence,population,procedures,cardiac,levels,complications,test,myocardial,control,type,hospitalization,number,correlates,trials,months,therapy,blood,heart,ventricular,summary,endpoints,activation,health,case,adjusted,frequencies,regions,distribution,estimated,left,primary,dose,cardiovascular,women,versus,angiographic,specific,diagnosed,odds,genes,hazards,drug,assessed,index,end,class,weeks,reported,severely,artery,india,infection,cohorts,country,participants,exercise,efficacy,presenting,non,infarction,comparative,flow,basic,events,failure,randomised,individual,survival,period,total,deaths,subjects,categories,operation,children,pressure,points,significantly,second,stroke,proportional,combined,month,selective,sensitivity,post,high,independent,acute,overall,sex,multivariable,major,stratified,subgroups,safety,multivariate,cox,regression,patients,logistic,analysis,year,rate,data,outcomes,age,results,adverse,\n",
      "Cluster 3 titles:count of adverse included in content 26\n",
      "Cluster 4 words:results,angiographic,test,patients,analysis,procedures,follow,study,coronial,groups,regression,summary,trials,treatment,clinician,months,exercise,multivariate,comparisons,model,measures,year,primary,cardiac,according,efficacy,basic,effectiveness,control,function,logistic,versus,days,hemodynamic,intervals,assessed,artery,case,weeks,comparative,related,outcomes,randomised,multivariable,post,subjects,events,predicted,categories,variable,overall,operation,endpoints,mortality,parameters,subgroups,risk,second,rate,ventricular,age,therapy,women,blood,correlates,selective,mean,time,myocardial,hospitalization,states,estimated,cox,class,sensitivity,value,type,diagnosed,stratified,number,data,non,individual,population,infection,medication,different,levels,india,acute,regions,association,month,dose,end,points,combined,index,cohorts,genes,left,cardiovascular,disease,total,factors,change,reported,children,safety,death,participants,flow,significantly,concentrations,response,activation,frequencies,severely,presenting,survival,prevalences,adjusted,proportional,incidence,specific,period,distribution,cause,country,health,stroke,high,infarction,heart,drug,failure,ratio,major,hazards,score,pressure,sex,deaths,complications,adverse,independent,odds,\n",
      "Cluster 4 titles:count of adverse included in content 1\n",
      "Cluster 5 words:events,adverse,treatment,clinician,patients,safety,groups,reported,follow,related,major,population,days,study,cardiac,summary,hospitalization,frequencies,incidence,drug,cardiovascular,year,weeks,number,period,months,according,effectiveness,rate,predicted,dose,randomised,analysis,cause,trials,severely,risk,association,class,participants,non,procedures,selective,month,coronial,type,specific,time,mortality,overall,stratified,acute,multivariate,different,complications,second,states,categories,score,medication,total,post,therapy,deaths,distribution,high,factors,death,age,disease,model,cohorts,outcomes,value,end,adjusted,control,survival,combined,results,assessed,primary,operation,endpoints,presenting,levels,versus,individual,regression,intervals,women,multivariable,independent,significantly,angiographic,data,proportional,prevalences,activation,test,comparative,ratio,hazards,subjects,comparisons,estimated,india,measures,logistic,basic,heart,index,cox,stroke,odds,subgroups,failure,regions,change,variable,efficacy,case,function,diagnosed,genes,pressure,sex,children,parameters,infarction,points,health,ventricular,artery,response,infection,blood,flow,exercise,concentrations,mean,myocardial,hemodynamic,country,left,sensitivity,correlates,\n",
      "Cluster 5 titles:count of adverse included in content 1101\n",
      "Cluster 6 words:patients,treatment,clinician,control,comparisons,groups,study,follow,coronial,heart,failure,events,parameters,disease,cardiac,variable,hospitalization,according,number,risk,effectiveness,subjects,versus,acute,randomised,myocardial,angiographic,predicted,mortality,medication,hemodynamic,therapy,related,time,function,frequencies,change,measures,rate,type,response,complications,death,diagnosed,factors,year,infarction,severely,exercise,population,ventricular,weeks,survival,incidence,distribution,levels,days,procedures,infection,different,presenting,index,left,score,states,mean,non,intervals,artery,proportional,trials,activation,comparative,class,months,value,cause,concentrations,assessed,subgroups,test,total,high,primary,stroke,blood,prevalences,major,month,summary,flow,drug,cardiovascular,significantly,association,end,basic,genes,age,specific,points,regions,analysis,cohorts,period,selective,operation,dose,india,stratified,correlates,ratio,multivariate,model,deaths,endpoints,second,estimated,case,sensitivity,categories,reported,adjusted,overall,individual,post,independent,pressure,efficacy,safety,hazards,outcomes,adverse,multivariable,data,combined,health,sex,country,cox,odds,results,regression,logistic,participants,women,children,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 6 titles:count of adverse included in content 14\n",
      "Cluster 7 words:age,year,rate,mortality,groups,sex,risk,adjusted,incidence,ratio,related,death,follow,according,cause,estimated,events,prevalences,number,heart,states,women,effectiveness,treatment,children,specific,country,population,change,disease,association,deaths,study,regions,predicted,case,diagnosed,intervals,survival,factors,days,cohorts,months,control,mean,hospitalization,health,score,blood,total,stratified,distribution,period,comparisons,individual,type,variable,different,overall,odds,model,pressure,hazards,response,time,infection,patients,clinician,india,cardiovascular,levels,function,coronial,categories,comparative,stroke,cardiac,medication,severely,class,proportional,selective,combined,major,participants,measures,trials,regression,randomised,non,analysis,versus,weeks,procedures,primary,high,value,reported,outcomes,independent,presenting,failure,parameters,infarction,basic,test,correlates,month,genes,subgroups,operation,therapy,ventricular,myocardial,multivariate,dose,concentrations,end,sensitivity,index,frequencies,activation,complications,significantly,summary,endpoints,left,subjects,efficacy,points,logistic,exercise,multivariable,data,post,artery,drug,acute,second,cox,hemodynamic,assessed,safety,results,flow,angiographic,adverse,\n",
      "Cluster 7 titles:count of adverse included in content 7\n"
     ]
    }
   ],
   "source": [
    "run_kmeans(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster : 8\n",
      "CPU times: user 20.4 s, sys: 125 ms, total: 20.6 s\n",
      "Wall time: 20.6 s\n",
      "4    16035\n",
      "3     3010\n",
      "2     1924\n",
      "7     1836\n",
      "1     1687\n",
      "6     1601\n",
      "0      957\n",
      "5      910\n",
      "Name: cluster, dtype: int64\n",
      "Top terms per clusters\n",
      "\n",
      "Cluster 0 words:variable,patients,clinician,association,hemodynamic,analysis,risk,related,heart,rate,effectiveness,correlates,measures,mortality,cardiac,change,comparisons,predicted,coronial,study,outcomes,mean,regression,time,value,model,ratio,according,disease,different,blood,age,groups,ventricular,subjects,intervals,factors,adjusted,flow,follow,function,exercise,events,procedures,control,death,independent,pressure,basic,selective,estimated,angiographic,year,significantly,left,myocardial,levels,distribution,survival,cause,test,genes,response,categories,score,data,index,treatment,artery,results,cardiovascular,logistic,therapy,population,states,assessed,specific,total,failure,multivariable,hazards,odds,presenting,primary,multivariate,class,severely,period,cohorts,sensitivity,number,combined,summary,women,prevalences,regions,stratified,versus,months,country,comparative,frequencies,case,days,hospitalization,dose,sex,infarction,weeks,concentrations,parameters,non,incidence,type,high,month,acute,activation,endpoints,individual,operation,points,medication,participants,overall,diagnosed,drug,efficacy,end,second,post,reported,health,stroke,randomised,infection,trials,children,cox,proportional,india,subgroups,safety,major,adverse,deaths,complications,\n",
      "Cluster 0 titles:count of adverse included in content 1\n",
      "Cluster 1 words:groups,treatment,patients,age,study,control,comparisons,outcomes,year,risk,mortality,according,rate,clinician,different,intervals,follow,mean,data,number,incidence,change,events,results,randomised,related,cause,sex,time,death,ratio,effectiveness,measures,months,score,states,adjusted,coronial,parameters,medication,hospitalization,analysis,primary,prevalences,disease,hemodynamic,days,value,trials,factors,comparative,distribution,population,women,deaths,index,second,period,procedures,exercise,dose,type,myocardial,total,predicted,function,variable,health,high,concentrations,heart,country,blood,specific,angiographic,cardiac,test,ventricular,frequencies,association,regions,end,survival,weeks,non,month,odds,points,versus,stratified,diagnosed,participants,left,response,case,complications,pressure,subjects,categories,activation,levels,endpoints,infarction,combined,drug,severely,proportional,post,estimated,summary,artery,reported,children,therapy,flow,presenting,individual,cardiovascular,hazards,overall,india,class,cohorts,sensitivity,basic,adverse,major,failure,assessed,model,operation,efficacy,acute,infection,genes,subgroups,selective,multivariate,stroke,safety,correlates,independent,significantly,regression,logistic,cox,multivariable,\n",
      "Cluster 1 titles:count of adverse included in content 15\n",
      "Cluster 2 words:analysis,regression,multivariate,predicted,cox,logistic,risk,factors,results,association,mortality,coronial,variable,patients,multivariable,death,events,year,outcomes,survival,hazards,related,angiographic,proportional,study,subgroups,clinician,effectiveness,age,sensitivity,cardiac,primary,follow,disease,rate,independent,population,cause,states,change,artery,adjusted,according,days,trials,time,significantly,control,heart,cardiovascular,second,parameters,presenting,score,efficacy,hospitalization,function,myocardial,ratio,data,overall,infarction,intervals,levels,case,versus,model,stroke,cohorts,value,months,points,concentrations,specific,post,test,left,endpoints,correlates,index,end,failure,major,summary,different,stratified,ventricular,randomised,assessed,basic,total,subjects,blood,number,measures,estimated,acute,response,incidence,sex,combined,regions,treatment,month,selective,comparative,weeks,prevalences,pressure,health,flow,comparisons,groups,participants,high,activation,children,operation,severely,procedures,individual,deaths,india,non,therapy,mean,women,odds,exercise,infection,diagnosed,period,type,dose,reported,hemodynamic,medication,complications,class,country,adverse,genes,categories,safety,frequencies,distribution,drug,\n",
      "Cluster 2 titles:count of adverse included in content 9\n",
      "Cluster 3 words:patients,clinician,data,outcomes,control,coronial,study,comparisons,follow,risk,events,hospitalization,disease,year,cardiac,angiographic,heart,results,mortality,according,versus,related,days,myocardial,failure,predicted,analysis,number,parameters,rate,randomised,therapy,effectiveness,time,subjects,death,factors,acute,function,infarction,procedures,hemodynamic,age,medication,artery,type,ventricular,exercise,test,change,levels,score,survival,measures,diagnosed,states,population,frequencies,left,complications,severely,trials,index,presenting,incidence,months,comparative,response,stroke,weeks,distribution,intervals,mean,cause,high,association,primary,ratio,non,class,total,subgroups,value,basic,different,stratified,summary,blood,flow,cardiovascular,month,proportional,operation,infection,major,cohorts,end,regions,activation,adjusted,individual,prevalences,assessed,significantly,points,concentrations,multivariate,specific,combined,period,dose,selective,endpoints,pressure,sensitivity,india,genes,overall,second,hazards,post,correlates,drug,case,independent,categories,deaths,estimated,safety,efficacy,model,reported,groups,sex,adverse,treatment,health,multivariable,country,regression,odds,logistic,variable,participants,cox,children,women,\n",
      "Cluster 3 titles:count of adverse included in content 17\n",
      "Cluster 4 words:outcomes,risk,year,clinician,age,study,related,mortality,effectiveness,association,data,rate,predicted,results,ratio,according,factors,disease,change,measures,coronial,follow,death,cause,days,score,adjusted,parameters,states,comparisons,incidence,function,intervals,hemodynamic,prevalences,hospitalization,primary,heart,population,procedures,months,number,test,time,angiographic,mean,different,women,estimated,specific,case,response,second,type,regions,medication,myocardial,levels,health,control,value,cardiac,blood,sex,ventricular,summary,trials,concentrations,diagnosed,left,therapy,odds,country,complications,cohorts,versus,correlates,children,distribution,activation,cardiovascular,efficacy,dose,infection,frequencies,participants,infarction,weeks,reported,endpoints,class,comparative,individual,deaths,severely,artery,end,india,survival,index,total,presenting,exercise,non,operation,drug,genes,categories,month,flow,basic,assessed,pressure,randomised,multivariate,failure,hazards,stratified,stroke,subjects,period,combined,selective,points,post,overall,high,significantly,sensitivity,acute,safety,subgroups,major,independent,proportional,regression,multivariable,adverse,logistic,cox,groups,patients,analysis,model,variable,treatment,events,\n",
      "Cluster 4 titles:count of adverse included in content 82\n",
      "Cluster 5 words:model,regression,cox,predicted,risk,hazards,logistic,multivariate,mortality,proportional,multivariable,adjusted,factors,death,variable,results,ratio,association,year,cause,cardiovascular,patients,independent,estimated,events,time,related,survival,outcomes,analysis,cardiac,hospitalization,effectiveness,age,score,basic,clinician,disease,states,coronial,heart,days,value,failure,intervals,different,change,study,stroke,measures,data,levels,odds,comparisons,incidence,myocardial,parameters,groups,total,non,comparative,overall,genes,follow,significantly,months,cohorts,rate,selective,children,combined,summary,india,test,population,infarction,case,function,treatment,acute,according,women,specific,end,categories,number,endpoints,points,artery,primary,versus,post,mean,severely,index,type,sex,response,month,deaths,country,randomised,presenting,left,health,regions,ventricular,major,control,correlates,therapy,stratified,operation,period,diagnosed,individual,hemodynamic,high,procedures,concentrations,subjects,prevalences,trials,class,participants,reported,assessed,infection,medication,complications,sensitivity,pressure,activation,angiographic,subgroups,blood,weeks,frequencies,flow,distribution,second,adverse,drug,exercise,efficacy,dose,safety,\n",
      "Cluster 5 titles:count of adverse included in content 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 6 words:treatment,patients,outcomes,effectiveness,analysis,population,events,clinician,study,year,days,according,response,weeks,rate,months,follow,primary,risk,time,change,trials,period,randomised,number,groups,related,states,failure,hospitalization,death,efficacy,mortality,incidence,different,medication,drug,ratio,adverse,comparative,second,versus,comparisons,infarction,myocardial,control,end,data,endpoints,mean,disease,measures,parameters,safety,assessed,results,estimated,heart,association,summary,type,overall,severely,subgroups,factors,dose,therapy,non,cohorts,prevalences,acute,stratified,survival,complications,coronial,age,adjusted,blood,score,post,concentrations,cause,function,children,levels,total,intervals,infection,angiographic,reported,hemodynamic,activation,month,proportional,specific,diagnosed,pressure,procedures,individual,basic,hazards,points,frequencies,cardiovascular,variable,subjects,stroke,value,deaths,class,women,case,left,test,combined,regions,presenting,predicted,index,flow,major,exercise,ventricular,participants,categories,selective,odds,operation,model,distribution,artery,genes,high,regression,health,sensitivity,significantly,country,cardiac,multivariate,multivariable,india,correlates,sex,independent,logistic,cox,\n",
      "Cluster 6 titles:count of adverse included in content 44\n",
      "Cluster 7 words:events,adverse,treatment,patients,clinician,follow,year,rate,related,major,cardiac,study,risk,days,cardiovascular,safety,population,groups,incidence,according,reported,predicted,hospitalization,summary,coronial,number,frequencies,association,period,months,outcomes,ratio,age,drug,time,cause,death,adjusted,weeks,mortality,trials,hazards,analysis,severely,primary,procedures,randomised,score,factors,dose,multivariate,type,month,stratified,participants,effectiveness,non,estimated,disease,second,therapy,states,heart,versus,class,women,overall,survival,cohorts,stroke,intervals,levels,medication,categories,selective,specific,presenting,results,prevalences,endpoints,post,end,acute,combined,different,data,basic,high,total,comparative,distribution,mean,independent,control,test,value,individual,concentrations,regression,infarction,points,complications,failure,myocardial,odds,case,diagnosed,deaths,subgroups,activation,proportional,assessed,comparisons,model,artery,regions,operation,angiographic,change,cox,sex,logistic,multivariable,efficacy,significantly,subjects,ventricular,parameters,measures,health,genes,pressure,india,blood,index,function,exercise,children,correlates,left,variable,sensitivity,flow,country,infection,hemodynamic,response,\n",
      "Cluster 7 titles:count of adverse included in content 1027\n"
     ]
    }
   ],
   "source": [
    "run_kmeans(count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize document clusters\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
