{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling for Finding Table Titles Relevant to Drug-Adverse Events\n",
    "\n",
    "- The following codes is implemented for topic modeling through LDA in attempt to find document samples(table title data) relevant to drug and adverse events.\n",
    "- Topic modeling is one of statistical modeling for discovering the abstract 'topics' that occur in a collection of document.\n",
    " - An example of topic model is used to classify text in a document to a particular topic\n",
    " - it builds a topic per document model and words per topic model, modeled as Dirichlet distributions\n",
    "- Following urls and research articles were referenced.\n",
    " - https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24\n",
    " - http://www.engear.net/wp/topic-modeling-gensimpython/\n",
    " - https://markroxor.github.io/gensim/static/notebooks/lda_training_tips.html\n",
    " - https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#14computemodelperplexityandcoherencescore\n",
    " - https://markroxor.github.io/gensim/static/notebooks/lda_training_tips.html\n",
    " - http://nbviewer.jupyter.org/github/bmabey/pyLDAvis/blob/master/notebooks/pyLDAvis_overview.ipynb\n",
    " - http://jeriwieringa.com/2018/07/17/pyLDAviz-and-Mallet/#comment-4018495276\n",
    " - https://ldavis.cpsievert.me/reviews/reviews.html\n",
    " - https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking if text is missing\n",
      "id       False\n",
      "title    False\n",
      "dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(27928, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retrieve table titles from csv\n",
    "data = pd.read_csv('titles_condition.tsv', delimiter='\\t', error_bad_lines=True, header=None)\n",
    "data.columns = ['id', 'title']\n",
    "data.title = data.title.str.strip()\n",
    "documents = data\n",
    "documents['title'].replace('', np.nan, inplace=True)\n",
    "documents = documents.astype(str)\n",
    "print('checking if text is missing')\n",
    "print(documents.isna().any())\n",
    "# documents.dropna(subset=['title'], inplace=True)\n",
    "documents.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Pre-processing\n",
    "- tokenization : \n",
    "  - split the text into sentences and then sentences into words\n",
    "  - lower case words\n",
    "  - remove punctuation\n",
    "  - remove words with fewer than 2 characters\n",
    "  - remove all stopwords + added ('table', 'legend')\n",
    "- Lemmatization : \n",
    " - verbs in past and future tenses are changed into present\n",
    "- Stemmazation :\n",
    " - words are reduced to their root form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.parsing.preprocessing import strip_numeric\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/grace/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(2018)\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "STOP_WORDS = list(gensim.parsing.preprocessing.STOPWORDS)\n",
    "STOP_WORDS.extend(['table', 'legend'])\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "#     deacc=True removes punctuations\n",
    "    for token in gensim.utils.simple_preprocess(text, deacc=True):\n",
    "        if token not in STOP_WORDS and len(token)>1:\n",
    "#             result.append(lemmatize_stemming(strip_numeric(token)))\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.49 s, sys: 24 ms, total: 6.51 s\n",
      "Wall time: 6.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#process the text, save the results as processed_docs\n",
    "processed_docs = pd.DataFrame()\n",
    "processed_docs = pd.concat([documents.id, documents.title.map(preprocess)], axis=1)\n",
    "processed_docs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trigram model : implement n-grams with Gensim Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING MIN_COUNT\n",
    "import itertools\n",
    "\n",
    "def check_trends_with_min_count(min_count):\n",
    "    bigram = gensim.models.Phrases(processed_docs.title, min_count=min_count, threshold=1)\n",
    "    trigram = gensim.models.Phrases(bigram[processed_docs.title], threshold=1)\n",
    "\n",
    "    #sentence clubbed as a trigram/bigram\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "    #generated n-grams\n",
    "    n_grams = []\n",
    "    word_2d = processed_docs.map(lambda x: trigram_mod[bigram_mod[x]])\n",
    "    for words in word_2d:\n",
    "        n_grams.extend(list(filter(lambda x : x.find('_')>=0, words)))\n",
    "    return set(n_grams)\n",
    "\n",
    "# n_gram_file = open('n_gram_by_min_count.csv', 'w')\n",
    "# test_min_counts = list(itertools.chain(range(1, 2), range(50, 500, 50)))\n",
    "# n_gram_matrix = []\n",
    "# matrix_index = 0\n",
    "# for i in reversed(test_min_counts):\n",
    "#     print('min_count %d' %i)\n",
    "#     print('matrix_index %d' %matrix_index)\n",
    "#     if matrix_index > 0:\n",
    "#         n_gram_matrix.append(list(set(check_trends_with_min_count(i)) - set(n_gram_matrix[matrix_index-1])))\n",
    "#     else:\n",
    "#         n_gram_matrix.append(list(set(check_trends_with_min_count(i))))\n",
    "#     n_gram_file.write(str(i)+'\\t'+str(n_gram_matrix[matrix_index])+'\\n')\n",
    "#     matrix_index += 1\n",
    "\n",
    "# n_gram_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.82 s, sys: 28 ms, total: 3.85 s\n",
      "Wall time: 3.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#min_count = ignore all words and bigrams with total collected count lower than this value\n",
    "#threshold = represent a score threshold for forming the phrases(higher means fewer phrases)\n",
    "bigram = gensim.models.Phrases(processed_docs.title, min_count=1, threshold=0.3)\n",
    "trigram = gensim.models.Phrases(bigram[processed_docs.title], threshold=0.3)\n",
    "\n",
    "#sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigram(text):\n",
    "    processed_text = [[word for word in simple_preprocess(str(doc)) if word not in STOP_WORDS] for doc in text]\n",
    "    return [bigram_mod[doc] for doc in processed_text]\n",
    "\n",
    "def make_trigram(text):\n",
    "    processed_text = [[word for word in simple_preprocess(str(doc)) if word not in STOP_WORDS] for doc in text]\n",
    "    return trigram_mod[[bigram_mod[doc] for doc in processed_text]]\n",
    "\n",
    "def explain_make_trigram(text):\n",
    "    conversion = {}\n",
    "    for doc in text:\n",
    "        pro_doc = simple_preprocess(str(doc))\n",
    "        if doc!= pro_doc:\n",
    "            print(doc)\n",
    "            print(pro_doc)\n",
    "            conversion[doc]=pro_doc\n",
    "    return conversion\n",
    "\n",
    "def n_gram_lemmatization(text, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    text_out = []\n",
    "    for sent in text:\n",
    "        doc = nlp(' '.join(sent))\n",
    "        text_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return text_out\n",
    "\n",
    "def explain_n_gram_lemmatization(text, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    conversions = {}\n",
    "    for sent in text:\n",
    "        doc = nlp(' '.join(sent))\n",
    "        for token in doc:\n",
    "            if len(token.lemma_) <4 and str(token)!=str(token.lemma_):\n",
    "                conversions[token] = token.lemma_\n",
    "#                 print('%s : %s' (token, token.lemma_))\n",
    "    return conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27928\n",
      "27928\n",
      "CPU times: user 7min 51s, sys: 15min 22s, total: 23min 14s\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "processed_bigram = n_gram_lemmatization(make_bigram(processed_docs.title))\n",
    "processed_trigram = n_gram_lemmatization(make_trigram(processed_docs.title))\n",
    "print(str(len(processed_bigram)))\n",
    "print(str(len(processed_trigram)))\n",
    "processed_docs['bigram'] = processed_bigram\n",
    "processed_docs['trigram'] = processed_trigram\n",
    "processed_docs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking bigram\n",
    "# count = 0\n",
    "# for ind, bigram in enumerate(processed_bigram):\n",
    "#     for bi in bigram:\n",
    "#         if bi.find('_')>=0:\n",
    "#             print(bi)\n",
    "#     if any(bi.find('_')>=0 for bi in bigram) and count<10:\n",
    "#         print(bigram)\n",
    "#         count +=1\n",
    "\n",
    "# for ind, trigram in enumerate(processed_trigram):\n",
    "#     for bi in trigram:\n",
    "#         if bi.find('_')>=0:\n",
    "#             print(bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bag of words on the data set\n",
    "- create a dictionary from 'processed_docs' containing the number of times a word appears in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the dictionary 9825\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "dictionary_made_by = processed_docs.title\n",
    "dictionary_made_by_str = 'unigram'#'bigram'#'trigram'\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(dictionary_made_by)\n",
    "print('size of the dictionary %d' %len(dictionary))\n",
    "max_dic_size = len(dictionary)\n",
    "test_dic_sizes = [max_dic_size, int(max_dic_size*2/3), int(max_dic_size/2), 10000]\n",
    "\n",
    "# count = 0\n",
    "# for k, v in dictionary.iteritems():\n",
    "#     if v.find('_')>=0:\n",
    "#         print(k,v)\n",
    "#     count += 1\n",
    "#     if count > 200:\n",
    "#         break\n",
    "#     if v.find('tion')>=0:\n",
    "#         print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out tokens that appear in less than 0.05 documents \n",
    "# or more than 0.5 documents\n",
    "# after above, keep only the first 40000 most frequent tokens.\n",
    "\n",
    "#############\n",
    "dict_size = test_dic_sizes[3]\n",
    "dictionary.filter_extremes(no_below=0.08, no_above=0.8, keep_n=dict_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 12 (\"pattern\") appears 1 times.\n",
      "Word 219 (\"initi\") appears 1 times.\n",
      "Word 297 (\"af\") appears 1 times.\n",
      "Word 302 (\"paramet\") appears 1 times.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>bigram</th>\n",
       "      <th>trigram</th>\n",
       "      <th>bow_corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4106</td>\n",
       "      <td>[analysi, efficaci]</td>\n",
       "      <td>[analysi_efficaci]</td>\n",
       "      <td>[analysi_efficaci]</td>\n",
       "      <td>[(0, 1), (1, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4107</td>\n",
       "      <td>[comparison, postop, ca, level, surviv, espac, conoko, jaspac, trial]</td>\n",
       "      <td>[comparison_postop, ca, level, surviv, espac, conoko, jaspac, trial]</td>\n",
       "      <td>[comparison_postop, ca, level, surviv, espac, conoko, jaspac, trial]</td>\n",
       "      <td>[(2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4108</td>\n",
       "      <td>[pattern, diseas, relaps]</td>\n",
       "      <td>[pattern_disea, relap]</td>\n",
       "      <td>[pattern_disea, relap]</td>\n",
       "      <td>[(11, 1), (12, 1), (13, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4109</td>\n",
       "      <td>[grade, advers, event, gemcitabin, gemcitabin, plus, capecitabin]</td>\n",
       "      <td>[grade_adver, event, gemcitabin, gemcitabin, plus_capecitabin]</td>\n",
       "      <td>[grade_advers_event, gemcitabin, gemcitabin, plus_capecitabin]</td>\n",
       "      <td>[(14, 1), (15, 1), (16, 1), (17, 2), (18, 1), (19, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4112</td>\n",
       "      <td>[treatment, zoledron, acid]</td>\n",
       "      <td>[treatment, zoledron_acid]</td>\n",
       "      <td>[treatment, zoledron_acid]</td>\n",
       "      <td>[(20, 1), (21, 1), (22, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4113</td>\n",
       "      <td>[treatment, docetaxel]</td>\n",
       "      <td>[treatment, docetaxel]</td>\n",
       "      <td>[treatment, docetaxel]</td>\n",
       "      <td>[(21, 1), (23, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4114</td>\n",
       "      <td>[treatment, relaps, discret, treat, clinician]</td>\n",
       "      <td>[treatment, relap, discret, treat, clinician]</td>\n",
       "      <td>[treatment, relap, discret, treat, clinician]</td>\n",
       "      <td>[(13, 1), (21, 1), (24, 1), (25, 1), (26, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4115</td>\n",
       "      <td>[worst, advers, event, grade, report, entir, time, trial]</td>\n",
       "      <td>[worst_adver, event_grade, report, entir, time_trial]</td>\n",
       "      <td>[worst_adver, event_grade, report, entir, time_trial]</td>\n",
       "      <td>[(10, 1), (14, 1), (16, 1), (18, 1), (27, 1), (28, 1), (29, 1), (30, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4117</td>\n",
       "      <td>[chemotherapi, deliveri, trial, drug, discontinu]</td>\n",
       "      <td>[chemotherapi_deliveri, trial_drug, discontinu]</td>\n",
       "      <td>[chemotherapi_deliveri, trial_drug, discontinu]</td>\n",
       "      <td>[(10, 1), (31, 1), (32, 1), (33, 1), (34, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4118</td>\n",
       "      <td>[advers, event]</td>\n",
       "      <td>[advers_event]</td>\n",
       "      <td>[advers_event]</td>\n",
       "      <td>[(14, 1), (16, 1)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  \\\n",
       "0  4106   \n",
       "1  4107   \n",
       "2  4108   \n",
       "3  4109   \n",
       "4  4112   \n",
       "5  4113   \n",
       "6  4114   \n",
       "7  4115   \n",
       "8  4117   \n",
       "9  4118   \n",
       "\n",
       "                                                                   title  \\\n",
       "0  [analysi, efficaci]                                                     \n",
       "1  [comparison, postop, ca, level, surviv, espac, conoko, jaspac, trial]   \n",
       "2  [pattern, diseas, relaps]                                               \n",
       "3  [grade, advers, event, gemcitabin, gemcitabin, plus, capecitabin]       \n",
       "4  [treatment, zoledron, acid]                                             \n",
       "5  [treatment, docetaxel]                                                  \n",
       "6  [treatment, relaps, discret, treat, clinician]                          \n",
       "7  [worst, advers, event, grade, report, entir, time, trial]               \n",
       "8  [chemotherapi, deliveri, trial, drug, discontinu]                       \n",
       "9  [advers, event]                                                         \n",
       "\n",
       "                                                                 bigram  \\\n",
       "0  [analysi_efficaci]                                                     \n",
       "1  [comparison_postop, ca, level, surviv, espac, conoko, jaspac, trial]   \n",
       "2  [pattern_disea, relap]                                                 \n",
       "3  [grade_adver, event, gemcitabin, gemcitabin, plus_capecitabin]         \n",
       "4  [treatment, zoledron_acid]                                             \n",
       "5  [treatment, docetaxel]                                                 \n",
       "6  [treatment, relap, discret, treat, clinician]                          \n",
       "7  [worst_adver, event_grade, report, entir, time_trial]                  \n",
       "8  [chemotherapi_deliveri, trial_drug, discontinu]                        \n",
       "9  [advers_event]                                                         \n",
       "\n",
       "                                                                trigram  \\\n",
       "0  [analysi_efficaci]                                                     \n",
       "1  [comparison_postop, ca, level, surviv, espac, conoko, jaspac, trial]   \n",
       "2  [pattern_disea, relap]                                                 \n",
       "3  [grade_advers_event, gemcitabin, gemcitabin, plus_capecitabin]         \n",
       "4  [treatment, zoledron_acid]                                             \n",
       "5  [treatment, docetaxel]                                                 \n",
       "6  [treatment, relap, discret, treat, clinician]                          \n",
       "7  [worst_adver, event_grade, report, entir, time_trial]                  \n",
       "8  [chemotherapi_deliveri, trial_drug, discontinu]                        \n",
       "9  [advers_event]                                                         \n",
       "\n",
       "                                                                  bow_corpus  \n",
       "0  [(0, 1), (1, 1)]                                                           \n",
       "1  [(2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1)]  \n",
       "2  [(11, 1), (12, 1), (13, 1)]                                                \n",
       "3  [(14, 1), (15, 1), (16, 1), (17, 2), (18, 1), (19, 1)]                     \n",
       "4  [(20, 1), (21, 1), (22, 1)]                                                \n",
       "5  [(21, 1), (23, 1)]                                                         \n",
       "6  [(13, 1), (21, 1), (24, 1), (25, 1), (26, 1)]                              \n",
       "7  [(10, 1), (14, 1), (16, 1), (18, 1), (27, 1), (28, 1), (29, 1), (30, 1)]   \n",
       "8  [(10, 1), (31, 1), (32, 1), (33, 1), (34, 1)]                              \n",
       "9  [(14, 1), (16, 1)]                                                         "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize\n",
    "# Bag-of-words representation of the documents\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in dictionary_made_by]\n",
    "\n",
    "bow_doc_100 = bow_corpus[100]\n",
    "for i in range(len(bow_doc_100)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} times.\".format(bow_doc_100[i][0],\n",
    "                                                     dictionary[bow_doc_100[i][0]],\n",
    "                                                     bow_doc_100[i][1]))\n",
    "\n",
    "processed_docs['bow_corpus'] = bow_corpus\n",
    "processed_docs.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF\n",
    "- tf-idf model on bow_corpus\n",
    "\n",
    "- tf = count(word, document) / len(document)\n",
    "- idf = log( len(collection) / count(document_containing_term, collection)\n",
    "- tf-idf = tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 12 (\"pattern\") appears 0.5663592984892322 times.\n",
      "Word 219 (\"initi\") appears 0.48898345095526347 times.\n",
      "Word 297 (\"af\") appears 0.5317609318755744 times.\n",
      "Word 302 (\"paramet\") appears 0.3966896028855394 times.\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "from pprint import pprint\n",
    "\n",
    "tfidf_mod = models.TfidfModel(bow_corpus)\n",
    "tfidf_corpus = tfidf_mod[bow_corpus]\n",
    "\n",
    "processed_docs['tfidf_corpus'] = tfidf_corpus\n",
    "tfidf_doc_100 = tfidf_corpus[100]\n",
    "for i in range(len(tfidf_doc_100)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} times.\".format(tfidf_doc_100[i][0],\n",
    "                                                     dictionary[tfidf_doc_100[i][0]],\n",
    "                                                     tfidf_doc_100[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 9825\n",
      "Number of documents bow corpus: 27928\n",
      "Number of documents tfidf: 27928\n",
      "Number of documents : 27928\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents bow corpus: %d' % len(bow_corpus))\n",
    "print('Number of documents tfidf: %d' % len(tfidf_corpus))\n",
    "print('Number of documents : %d' % len(dictionary_made_by))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal number of topics\n",
    "- build many LDA models with different values of number of topics and pick the one that gives the highest coherence value based on corpus\n",
    "- 토픽 모델링 결과로 나온 주제들에 대해 각각의 주제에서 상위 N개의 단어를 뽑습니다. 모델링이 잘 되었을수록 한 주제 안에는 의미론적으로 유사한 단어가 많이 모여있게 마련입니다. 따라서 상위 단어 간의 유사도를 계산하면 실제로 해당 주제가 의미론적으로 일치하는 단어들끼리 모여있는지 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_coherence_values(model_type, dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    compute c_v coherence for various number of topics\n",
    "    \n",
    "    parameters:\n",
    "    dictionary : gensim dictionary\n",
    "    corpus : gensim corpus\n",
    "    texts : list of input texts\n",
    "    limit : max number of topics\n",
    "    \n",
    "    returns:\n",
    "    model_list : list of LDA topic models\n",
    "    coherence_values : coherence value\n",
    "    \"\"\"\n",
    "    \n",
    "    coherenece_values = []\n",
    "    u_mass_coherenece_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        if model_type == 'mallet':\n",
    "            model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, \\\n",
    "                                                     num_topics=num_topics, \\\n",
    "                                                     id2word=dictionary, workers=8, \\\n",
    "                                                     iterations=60)\n",
    "        elif model_type == 'online':\n",
    "            model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, \\\n",
    "                                                    num_topics=num_topics, update_every=0, \\\n",
    "                                                    passes=20)\n",
    "        else:\n",
    "            model = gensim.models.LdaMulticore(corpus, num_topics=num_topics, \\\n",
    "                                               id2word=dictionary, passes=2, \\\n",
    "                                               workers=8, iterations=60)\n",
    "        \n",
    "        model_list.append(model)\n",
    "        coherence_model = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        u_mass_coherence_model = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='u_mass')\n",
    "        \n",
    "        coherenece_values.append(coherence_model.get_coherence())\n",
    "        u_mass_coherenece_values.append(u_mass_coherence_model.get_coherence())\n",
    "\n",
    "    return model_list, coherenece_values, u_mass_coherenece_values\n",
    "\n",
    "def find_optimal_topic_num(model_type, model_list, coherence_values, umass_co_val):   \n",
    "    #graph\n",
    "    print('======== '+model_type + ' ========')\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "    x = range(start, limit, step)\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.plot(x, coherence_values)\n",
    "    ax1.set_xlabel(\"Number of Topics\")\n",
    "    ax1.set_ylabel(\"Coherence score\")\n",
    "    #     plt.legend((\"coherence_values\"), loc=\"best\")\n",
    "\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.plot(x, umass_co_val)\n",
    "    ax2.set_xlabel(\"Number of Topics\")\n",
    "    ax2.set_ylabel(\"u mass Coherence score\")\n",
    "    #     plt.legend((\"u mass coherence_values\"), loc=\"best\")\n",
    "\n",
    "    fig.savefig(directory+'/'+model_type+'_coherence.png')\n",
    "\n",
    "    # Print the coherence scores\n",
    "    # one that maximizes the topic coherence\n",
    "    print('Coherence c_v ================')\n",
    "    max_coherence_topic_num = 8 #default\n",
    "    prev_co = 0\n",
    "    first_max_cohe_found = False\n",
    "    for m, cv in zip(x, coherence_values):\n",
    "        cur_coherence = round(cv, 4)\n",
    "        print(\"Num Topics =\", m, \" has Coherence cv Value of\", cur_coherence)\n",
    "#         if (cur_coherence > 0.32) and m > 5:\n",
    "        if m > 5:\n",
    "            if (prev_co <= cur_coherence) and not first_max_cohe_found:\n",
    "                max_coherence_topic_num = m\n",
    "            else:\n",
    "                first_max_cohe_found = True\n",
    "        prev_co = cur_coherence\n",
    "    print('Best number of topic is : %d' %max_coherence_topic_num)\n",
    "\n",
    "    print('Coherence umass ================')\n",
    "    #where score plateaus안정\n",
    "    for m, um in zip(x, umass_co_val):\n",
    "        print(\"Num Topics =\", m, \" has Coherence umass Value of\", round(um, 4))\n",
    "    \n",
    "    return max_coherence_topic_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config='dic_'+dictionary_made_by_str+'_size_'+str(len(dictionary))\n",
    "mallet_path = './mallet-2.0.8/bin/mallet'\n",
    "\n",
    "import os\n",
    "directory ='./stat_files/'+model_config\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== mallet ========\n",
      "Coherence c_v ================\n",
      "Num Topics = 2  has Coherence cv Value of 0.146\n",
      "Num Topics = 3  has Coherence cv Value of 0.1208\n",
      "Num Topics = 4  has Coherence cv Value of 0.1705\n",
      "Num Topics = 5  has Coherence cv Value of 0.1708\n",
      "Num Topics = 6  has Coherence cv Value of 0.2473\n",
      "Num Topics = 7  has Coherence cv Value of 0.2466\n",
      "Num Topics = 8  has Coherence cv Value of 0.2799\n",
      "Num Topics = 9  has Coherence cv Value of 0.2568\n",
      "Num Topics = 10  has Coherence cv Value of 0.2543\n",
      "Num Topics = 11  has Coherence cv Value of 0.2679\n",
      "Num Topics = 12  has Coherence cv Value of 0.3233\n",
      "Num Topics = 13  has Coherence cv Value of 0.2998\n",
      "Num Topics = 14  has Coherence cv Value of 0.3115\n",
      "Num Topics = 15  has Coherence cv Value of 0.2552\n",
      "Num Topics = 16  has Coherence cv Value of 0.2645\n",
      "Num Topics = 17  has Coherence cv Value of 0.2729\n",
      "Num Topics = 18  has Coherence cv Value of 0.2845\n",
      "Num Topics = 19  has Coherence cv Value of 0.3053\n",
      "Num Topics = 20  has Coherence cv Value of 0.2915\n",
      "Num Topics = 21  has Coherence cv Value of 0.2858\n",
      "Num Topics = 22  has Coherence cv Value of 0.2985\n",
      "Num Topics = 23  has Coherence cv Value of 0.2759\n",
      "Num Topics = 24  has Coherence cv Value of 0.2913\n",
      "Best number of topic is : 6\n",
      "Coherence umass ================\n",
      "Num Topics = 2  has Coherence umass Value of -3.1722\n",
      "Num Topics = 3  has Coherence umass Value of -3.3373\n",
      "Num Topics = 4  has Coherence umass Value of -3.2766\n",
      "Num Topics = 5  has Coherence umass Value of -3.6119\n",
      "Num Topics = 6  has Coherence umass Value of -3.5639\n",
      "Num Topics = 7  has Coherence umass Value of -3.5879\n",
      "Num Topics = 8  has Coherence umass Value of -3.7829\n",
      "Num Topics = 9  has Coherence umass Value of -3.7741\n",
      "Num Topics = 10  has Coherence umass Value of -3.8504\n",
      "Num Topics = 11  has Coherence umass Value of -4.0485\n",
      "Num Topics = 12  has Coherence umass Value of -4.4949\n",
      "Num Topics = 13  has Coherence umass Value of -4.2926\n",
      "Num Topics = 14  has Coherence umass Value of -4.6783\n",
      "Num Topics = 15  has Coherence umass Value of -4.5517\n",
      "Num Topics = 16  has Coherence umass Value of -4.4461\n",
      "Num Topics = 17  has Coherence umass Value of -4.9995\n",
      "Num Topics = 18  has Coherence umass Value of -5.1849\n",
      "Num Topics = 19  has Coherence umass Value of -5.1207\n",
      "Num Topics = 20  has Coherence umass Value of -4.9653\n",
      "Num Topics = 21  has Coherence umass Value of -5.5592\n",
      "Num Topics = 22  has Coherence umass Value of -5.4398\n",
      "Num Topics = 23  has Coherence umass Value of -5.4682\n",
      "Num Topics = 24  has Coherence umass Value of -5.824\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%time\n",
    "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "limit = 25; start=2; step=1;\n",
    "\n",
    "# model_list_on, coherence_values_on, umass_co_val_on = compute_coherence_values(model_type='online', dictionary=dictionary, \\\n",
    "#                                                                       corpus=bow_corpus, \\\n",
    "#                                                                       texts=dictionary_made_by, \\\n",
    "#                                                                       start=start, \\\n",
    "#                                                                       limit=limit, \\\n",
    "#                                                                       step=step)\n",
    "# max_coherence_topic_num_on= find_optimal_topic_num('online', model_list_on, coherence_values_on, umass_co_val_on)\n",
    "\n",
    "model_list, coherence_values, umass_co_val = compute_coherence_values(model_type='mallet', dictionary=dictionary, \\\n",
    "                                                                      corpus=bow_corpus, \\\n",
    "                                                                      texts=dictionary_made_by, \\\n",
    "                                                                      start=start, \\\n",
    "                                                                      limit=limit, \\\n",
    "                                                                      step=step)\n",
    "max_coherence_topic_num = find_optimal_topic_num('mallet', model_list, coherence_values, umass_co_val)\n",
    "\n",
    "# model_list_tfidf, coherence_values_tfidf, umass_co_val_tfidf = compute_coherence_values(model_type='tfidf', dictionary=dictionary, \\\n",
    "#                                                                                               corpus=tfidf_corpus, \\\n",
    "#                                                                                               texts=dictionary_made_by, \\\n",
    "#                                                                                               start=start, \\\n",
    "#                                                                                               limit=limit, \\\n",
    "#                                                                                               step=step)\n",
    "# max_coherence_topic_num_tfidf = find_optimal_topic_num('tfidf', model_list_tfidf, coherence_values_tfidf, umass_co_val_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA using bag of words\n",
    "\n",
    "- train LDA using gensim.models.LdaMulticore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda_model_bow = gensim.models.LdaMulticore(bow_corpus, num_topics=8, id2word=dictionary, passes=2, workers=2)\n",
    "# for idx, topic in lda_model_bow.print_topics(-1):\n",
    "#     print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "\n",
    "\n",
    "#is mallet better?\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "dir_to_check = Path(directory+'/data/')\n",
    "if not dir_to_check.is_dir():\n",
    "    os.makedirs(directory+'/data/')\n",
    "    \n",
    "def get_optimal_model(model_type, optimal_topic_num):\n",
    "#     optimal_topic_num = max_coherence_topic_num\n",
    "    if model_type=='mallet':\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path=mallet_path, \\\n",
    "                                                      corpus=bow_corpus, \\\n",
    "                                                      num_topics=optimal_topic_num, \\\n",
    "                                                      id2word=dictionary,\\\n",
    "                                                      iterations=100,\\\n",
    "                                                      prefix=directory+'/data/')\n",
    "    elif model_type=='online':\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=bow_corpus, id2word=dictionary, \\\n",
    "                                                    num_topics=optimal_topic_num, update_every=0, \\\n",
    "                                                    passes=20)\n",
    "    else:\n",
    "        model = gensim.models.LdaMulticore(tfidf_corpus,\\\n",
    "                                             num_topics=optimal_topic_num, \\\n",
    "                                             id2word=dictionary, \\\n",
    "                                             passes=2, \\\n",
    "                                             workers=8,\\\n",
    "                                            iterations=100)\n",
    "        \n",
    "    #show topics\n",
    "    topics = model.show_topics(formatted=False)\n",
    "    pprint(topics)\n",
    "    # lda_mallet.save('./data/mallet_topics_num_'+str(optimal_topic_num)+'_'+model_config+'.state.gz')\n",
    "#     model.load_word_topics()\n",
    "  \n",
    "    fig = plt.figure(figsize=(15,20))\n",
    "    fig.suptitle(model_type+'_topics_num_'+str(optimal_topic_num)+'_'+model_config)\n",
    "\n",
    "    for i in range(optimal_topic_num):\n",
    "        df=pd.DataFrame(model.show_topic(i), columns=['term','prob']).set_index('term')\n",
    "\n",
    "        axi = fig.add_subplot(math.ceil(optimal_topic_num/2),2,i+1)\n",
    "        axi.set_title('topic '+str(i+1))\n",
    "        sns.barplot(x='prob', y=df.index, data=df, palette='Reds_d')\n",
    "        axi.set_xlabel('probability')\n",
    "\n",
    "    # plt.show()\n",
    "    fig.savefig(directory+'/'+model_type+'_topics_num_'+str(optimal_topic_num)+'.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_coherence_topic_num = 8\n",
    "# max_coherence_topic_num_on = 8\n",
    "# max_coherence_topic_num_tfidf = 8\n",
    "\n",
    "mallet_model = get_optimal_model('mallet', max_coherence_topic_num)\n",
    "on_model = get_optimal_model('online', max_coherence_topic_num_on)\n",
    "tfidf_model = get_optimal_model('tfidf', max_coherence_topic_num_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator \n",
    "\n",
    "def draw_duplicate_keywords_bar(model_type, optimal_topic_num, duplicate_keywords):\n",
    "    plt.style.use('ggplot')\n",
    "\n",
    "    x = duplicate_keywords.keys()\n",
    "    x_values = [item[1] for item in duplicate_keywords.items()]\n",
    "    x_pos = [i for i in range(len(x))]\n",
    "\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    plt.bar(x_pos, x_values, color='green')\n",
    "    plt.xlabel(\"Duplicate Keywords\")\n",
    "    plt.ylabel(\"Num Duplication\")\n",
    "    plt.title(\"Duplicate Keywords_\" + model_type)\n",
    "\n",
    "    plt.xticks(x_pos, x)\n",
    "    plt.show()\n",
    "    fig.savefig(directory+'/'+model_type+'_duplicate_keywords'+str(optimal_topic_num)+'.png')\n",
    "    \n",
    "def check_duplicate_keywords(model_type, optimal_topic_num, topics):\n",
    "    all_keywords = {}\n",
    "    for topic in topics:\n",
    "        for t in topic[1]:\n",
    "            keyword = t[0]\n",
    "            if keyword in all_keywords.keys():\n",
    "                all_keywords[keyword] = all_keywords[keyword] + 1\n",
    "            else:\n",
    "                all_keywords[keyword] = 1\n",
    "    \n",
    "    duplicates= dict(filter(lambda x: x[1] > 1, \\\n",
    "           sorted(all_keywords.items(), key=operator.itemgetter(1), reverse=True)))\n",
    "    draw_duplicate_keywords_bar(model_type, optimal_topic_num, duplicates)\n",
    "    return duplicates\n",
    "\n",
    "\n",
    "duplicate_keywords_mallet = check_duplicate_keywords(\"mallet\", max_coherence_topic_num, mallet_model.show_topics(formatted=False))\n",
    "duplicate_keywords_on = check_duplicate_keywords(\"online\", max_coherence_topic_num_on, on_model.show_topics(formatted=False))\n",
    "duplicate_keywords_tfidf = check_duplicate_keywords(\"tfidf\", max_coherence_topic_num_tfidf, tfidf_model.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_keywords(model_type, topics, duplicate_keywords):\n",
    "#     print(list(map(lambda x: x[1][0], topics)))\n",
    "#     for t in topics:\n",
    "#         print(list(map(lambda x: x[0], t[1])))\n",
    "#     print('=================')\n",
    "    keyword_df = pd.DataFrame(list(map(lambda s: [s[0], list(map(lambda x: x[0], s[1]))], \\\n",
    "                                 topics)))\n",
    "    keyword_df.columns = ['topic', 'keywords']\n",
    "    duplicate_removed = []\n",
    "    for indx, row in keyword_df.iterrows():\n",
    "        duplicate_removed.append(list(filter(lambda x: x not in duplicate_keywords, row.keywords)))\n",
    "\n",
    "    keyword_df['unique_keywords'] = pd.Series(duplicate_removed, index=keyword_df.index)\n",
    "    print(keyword_df)\n",
    "    keyword_df.to_html(directory+'/'+model_type+'_unique_keywords.html', index=False)\n",
    "    \n",
    "get_unique_keywords(\"mallet\", mallet_model.show_topics(formatted=False), duplicate_keywords_mallet)\n",
    "get_unique_keywords(\"online\", on_model.show_topics(formatted=False), duplicate_keywords_on)\n",
    "get_unique_keywords(\"tfidf\", tfidf_model.show_topics(formatted=False), duplicate_keywords_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Check topic distribution of a sample data\n",
    "# for ind, score in sorted(lda_mallet[bow_corpus[45]], key=lambda x: -1*x[1]):\n",
    "#     print('\\nScore: {}\\t \\nTopic: {}'.format(score, lda_mallet.print_topic(ind, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "\n",
    "dataDir = directory+'/data/'\n",
    "\n",
    "def extract_params(statefile):\n",
    "    \"\"\"extract alpha and beta values from MALLET statefile by path to statfile\n",
    "    \n",
    "    Args:\n",
    "        statefile (str) : Path to statefile produced by MALLET\n",
    "    Returns:\n",
    "        tuple: alpha (list), beta\n",
    "    \"\"\"\n",
    "    \n",
    "#     with codecs.open(statefile, \"r\",encoding='utf-8') as state:\n",
    "    with gzip.open(statefile, 'r') as state:\n",
    "        params = [x.decode('utf-8').strip() for x in state.readlines()[1:3]]\n",
    "#         params = [x.strip() for x in state.readlines()[1:3]]\n",
    "    return (list(params[0].split(':')[1].split(\" \")), float(params[1].split(':')[1]))\n",
    "\n",
    "def state_to_df(statefile):\n",
    "    \"\"\"transform state file into pandas dataframe\n",
    "    the MALLET statefile is tab-separated, and the first two rows contain the alpha and beta parameters\n",
    "    \n",
    "    Args:\n",
    "        statefile (str): Path to statefile produced by MALLET\n",
    "    Returns:\n",
    "        dataframe: topic assignment for each token in each documnet of the model\n",
    "    \"\"\"\n",
    "    return pd.read_csv(statefile,\\\n",
    "                      compression='gzip',\\\n",
    "                      sep=' ',\\\n",
    "                      skiprows=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = extract_params(os.path.join(dataDir, 'state.mallet.gz'))\n",
    "alpha = [float(x) for x in params[0][1:]]\n",
    "beta = params[1]\n",
    "print(\"{}, {}\".format(alpha, beta))\n",
    "\n",
    "df = state_to_df(os.path.join(dataDir, 'state.mallet.gz'))\n",
    "df['type'] = df.type.astype(str)\n",
    "df[:5]\n",
    "#doc id, word position index, word index, topic assignmnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get the length of the document, group by the document id and count the tokens\n",
    "docs = df.groupby('#doc')['type'].count().reset_index(name='doc_length')\n",
    "docs[:10]\n",
    "\n",
    "#get vocab and term frequencies\n",
    "vocab = df['type'].value_counts().reset_index()\n",
    "vocab.columns = ['type', 'term_freq']\n",
    "vocab = vocab.sort_values(by='type', ascending=True)\n",
    "vocab[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matrix file\n",
    "#need to normalize data so that each row sums to 1\n",
    "import sklearn.preprocessing\n",
    "\n",
    "def pivot_and_smooth(df, smooth_values, rows_variable, cols_variable, values_variable):\n",
    "    \"\"\"\n",
    "    modify dataframe into matrix\n",
    "    Args:\n",
    "        df (dataframe) : \n",
    "        smooth_values (float) : value to add to the matrix to account for the priors\n",
    "        rows_variable (str) : title of rows\n",
    "        cols_variable (str) : title of columns\n",
    "        values_variable (str) : values\n",
    "    Returns:\n",
    "        dataframe : that has been normalized on the rows.\n",
    "    \"\"\"\n",
    "    matrix = df.pivot(index=rows_variable, columns=cols_variable, values=values_variable).fillna(value=0)\n",
    "    matrix = matrix.values + smooth_values\n",
    "    \n",
    "    normed = sklearn.preprocessing.normalize(matrix, norm='l1', axis=1)\n",
    "    \n",
    "    return pd.DataFrame(normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the number of topic assingments for words in documents\n",
    "#phi - topic-term matrix and counted the number of times each word was assigned to each topic \n",
    "#and sorted by alphabetically to match the order of the vocabulary frame\n",
    "\n",
    "#beta as the smoothign value\n",
    "phi_df = df.groupby(['topic', 'type'])['type'].count().reset_index(name='token_count')\n",
    "phi_df = phi_df.sort_values(by='type', ascending=True)\n",
    "phi_df[:5]\n",
    "\n",
    "phi = pivot_and_smooth(phi_df, beta, 'topic', 'type', 'token_count')\n",
    "phi[:5]\n",
    "\n",
    "#theta document-topic matrix and use alpha as the smoothign value\n",
    "theta_df = df.groupby(['#doc', 'topic'])['topic'].count().reset_index(name='topic_count')\n",
    "theta_df[:5]\n",
    "\n",
    "theta = pivot_and_smooth(theta_df, alpha, '#doc', 'topic', 'topic_count')\n",
    "theta[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_mallet_data = {\n",
    "    'topic_term_dists':phi,\n",
    "    'doc_topic_dists':theta,\n",
    "    'doc_lengths':list(docs['doc_length']),\n",
    "    'vocab':list(vocab['type']),\n",
    "    'term_frequency':list(vocab['term_freq'])\n",
    "}\n",
    "mallet_vis_data = pyLDAvis.prepare(**lda_mallet_data)\n",
    "pyLDAvis.display(mallet_vis_data)\n",
    "pyLDAvis.save_html(mallet_vis_data, directory+'/mallet_topics_num_'+str(max_coherence_topic_num)+'.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each bubble = topic, the larger the bubble, the more prevalent is that topic\n",
    "#good topic = fairly big, non-overlapping bubbles scattered throughout the chart\n",
    "#model with too many topics = typically have many overlaps, small sized bubbles in one region of the chart\n",
    "data_tfidf = pyLDAvis.gensim.prepare(tfidf_model, tfidf_corpus, dictionary)\n",
    "data_tfidf\n",
    "\n",
    "#bar = salient keywords that form the selected topic\n",
    "pyLDAvis.display(data_tfidf)\n",
    "pyLDAvis.save_html(data_tfidf, directory+'/tfidf_topics_num_'+str(max_coherence_topic_num_tfidf)+'.html')\n",
    "\n",
    "data_on = pyLDAvis.gensim.prepare(on_model, bow_corpus, dictionary)\n",
    "data_on\n",
    "\n",
    "pyLDAvis.display(data_on)\n",
    "pyLDAvis.save_html(data_on, directory+'/online_topics_num_'+str(max_coherence_topic_num_on)+'.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perplexity and Coherence score\n",
    "- model perplexity and topic coherence provide a convenient measure to judge how good a given topic model is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute perplexity : a measure of how good the model is\n",
    "# lower the better\n",
    "# print('\\nPerplexit: ', lda_mallet.log_perplexity(bow_corpus))\n",
    "# print('\\nPerplexit: ', lda_model_tfidf.log_perplexity(bow_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "#compute coherence score\n",
    "coherence_model_lda = CoherenceModel(model=mallet_model, texts=processed_trigram, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "#compute coherence score\n",
    "coherence_model_lda_tfidf = CoherenceModel(model=tfidf_model, texts=processed_trigram, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda_tfidf = coherence_model_lda_tfidf.get_coherence()\n",
    "print('\\nTF-IDF Coherence Score: ', coherence_lda_tfidf)\n",
    "\n",
    "#compute coherence score\n",
    "coherence_model_lda_on = CoherenceModel(model=on_model, texts=processed_trigram, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda_on = coherence_model_lda_on.get_coherence()\n",
    "print('\\nONLINE Coherence Score: ', coherence_lda_on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find dominant topic\n",
    "- find the most contributed topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = processed_docs.merge(documents, on='id')\n",
    "# test = processed_docs[['id', 'title_x', 'bow_corpus', 'title_y']]\n",
    "# test.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs.iloc[151]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def format_topics_sentences(model, \\\n",
    "                            model_type='mallet', \\\n",
    "                            corpus=processed_docs, \\\n",
    "                            texts=dictionary_made_by):\n",
    "    sent_topic_df = pd.DataFrame()\n",
    "    if model_type=='tfidf':\n",
    "        target_corpus = corpus.tfidf_corpus\n",
    "    else:\n",
    "        target_corpus = corpus.bow_corpus\n",
    "    \n",
    "    for i, row in enumerate(model[target_corpus]):\n",
    "        origin_info = processed_docs.iloc[i]\n",
    "        text_vec = texts[i]\n",
    "        #get main topic in each document\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j==0: #dominant topic\n",
    "                wp = model.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "#                 print(pd.Series([origin_info.id,\\\n",
    "#                                 int(topic_num), \\\n",
    "#                                 round(prop_topic, 4), \\\n",
    "#                                 topic_keywords, \\\n",
    "#                                origin_info.title_y, \\\n",
    "#                                text_vec]))\n",
    "                sent_topic_df = sent_topic_df.append(pd.Series([origin_info.id,\\\n",
    "                                                                int(topic_num), \\\n",
    "                                                                round(prop_topic, 4), \\\n",
    "                                                                topic_keywords, \\\n",
    "                                                               origin_info.title_y, \\\n",
    "                                                               text_vec]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topic_df.columns = ['id', 'Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords', 'Origin_Text', 'Text_Vec']\n",
    "    \n",
    "    return (sent_topic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords_mallet = format_topics_sentences(model=mallet_model, \\\n",
    "                                                  corpus=processed_docs, \\\n",
    "                                                  texts=dictionary_made_by, \\\n",
    "                                                 model_type='mallet')\n",
    "df_topic_sents_keywords_mallet.head(max_coherence_topic_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords_tfidf = format_topics_sentences(model=tfidf_model, \\\n",
    "                                                  corpus=processed_docs, \\\n",
    "                                                  texts=dictionary_made_by, \\\n",
    "                                                 model_type='tfidf')\n",
    "df_topic_sents_keywords_tfidf.head(max_coherence_topic_num_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords_on = format_topics_sentences(model=on_model, \\\n",
    "                                                  corpus=processed_docs, \\\n",
    "                                                  texts=dictionary_made_by, \\\n",
    "                                                 model_type='online')\n",
    "df_topic_sents_keywords_on.head(max_coherence_topic_num_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_topic_sents_keywords_mallet.isna().any())\n",
    "print('=================')\n",
    "print(df_topic_sents_keywords_tfidf.isna().any())\n",
    "print('=================')\n",
    "print(df_topic_sents_keywords_on.isna().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 각 토픽별로 가장 대표적인 문서 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rep_sents(keywords, model_type):\n",
    "    sent_topics_sorted_df_mallet = pd.DataFrame()\n",
    "    \n",
    "    sent_topics_groupby = keywords.groupby('Dominant_Topic')\n",
    "\n",
    "    keywords_top = pd.DataFrame()\n",
    "    for i, grp in sent_topics_groupby:\n",
    "        keywords_top = pd.concat([keywords_top, \\\n",
    "                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(20)], \\\n",
    "                            axis=0)\n",
    "        keywords = pd.concat([keywords, \\\n",
    "                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(20)], \\\n",
    "                            axis=0)\n",
    "\n",
    "    keywords_top.reset_index(drop=True, inplace=True)\n",
    "    keywords_top.columns = ['id', 'Topic_Num', 'Topic_Perc_Contribu', 'Topic_Keywords', 'Origin_Text', 'Text']\n",
    "    keywords_top.to_csv(directory+'/'+model_type+'_top_sen.tsv', sep='\\t')\n",
    "    \n",
    "    keywords.reset_index(drop=True, inplace=True)\n",
    "    keywords.columns = ['id', 'Topic_Num', 'Topic_Perc_Contribu', 'Topic_Keywords', 'Origin_Text', 'Text']\n",
    "    \n",
    "    return keywords\n",
    "    \n",
    "df_topic_sents_mallet = get_rep_sents(df_topic_sents_keywords_mallet, 'mallet')\n",
    "df_topic_sents_tfidf = get_rep_sents(df_topic_sents_keywords_tfidf, 'tfidf')\n",
    "df_topic_sents_on = get_rep_sents(df_topic_sents_keywords_on, 'online')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords_mallet.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_mallet.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_tfidf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_tfidf.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문서 전체적인 토픽 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_counts = df_topic_sents_mallet['Topic_Num'].value_counts()\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "topic_num_keywords = df_topic_sents_mallet[['Topic_Num', 'Topic_Keywords']]\n",
    "\n",
    "df_dominant_topics = pd.concat([topic_counts, topic_contribution], axis=1)\n",
    "df_dominant_topics.reset_index(level=0, inplace=True)\n",
    "df_dominant_topics.columns = ['Topic_Num', 'Num_Documents', 'Perc_Documents']\n",
    "df_dominant_topics = df_dominant_topics.merge(topic_num_keywords.drop_duplicates(), on='Topic_Num')\n",
    "df_dominant_topics = df_dominant_topics.sort_values('Topic_Num')\n",
    "\n",
    "df_dominant_topics.reset_index(drop = True, inplace = True)\n",
    "df_dominant_topics.to_html(directory+'/mallet_distribution.html', index=False)\n",
    "df_dominant_topics.head(max_coherence_topic_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_counts = df_topic_sents_tfidf['Topic_Num'].value_counts()\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "topic_num_keywords = df_topic_sents_tfidf[['Topic_Num', 'Topic_Keywords']]\n",
    "\n",
    "df_dominant_topics = pd.concat([topic_counts, topic_contribution], axis=1)\n",
    "df_dominant_topics.reset_index(level=0, inplace=True)\n",
    "df_dominant_topics.columns = ['Topic_Num', 'Num_Documents', 'Perc_Documents']\n",
    "df_dominant_topics = df_dominant_topics.merge(topic_num_keywords.drop_duplicates(), on='Topic_Num')\n",
    "df_dominant_topics = df_dominant_topics.sort_values('Topic_Num')\n",
    "\n",
    "df_dominant_topics.reset_index(drop = True, inplace = True)\n",
    "df_dominant_topics.to_html(directory+'/tfidf_distribution.html', index=False)\n",
    "df_dominant_topics.head(max_coherence_topic_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_counts = df_topic_sents_on['Topic_Num'].value_counts()\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "topic_num_keywords = df_topic_sents_on[['Topic_Num', 'Topic_Keywords']]\n",
    "\n",
    "df_dominant_topics = pd.concat([topic_counts, topic_contribution], axis=1)\n",
    "df_dominant_topics.reset_index(level=0, inplace=True)\n",
    "df_dominant_topics.columns = ['Topic_Num', 'Num_Documents', 'Perc_Documents']\n",
    "df_dominant_topics = df_dominant_topics.merge(topic_num_keywords.drop_duplicates(), on='Topic_Num')\n",
    "df_dominant_topics = df_dominant_topics.sort_values('Topic_Num')\n",
    "\n",
    "df_dominant_topics.reset_index(drop = True, inplace = True)\n",
    "df_dominant_topics.to_html(directory+'/on_distribution.html', index=False)\n",
    "df_dominant_topics.head(max_coherence_topic_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://ai.googleblog.com/2016/12/open-sourcing-embedding-projector-tool.html\n",
    "- http://projector.tensorflow.org/\n",
    "- http://nbviewer.jupyter.org/github/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb#loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
