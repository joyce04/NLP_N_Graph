{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqxFVlDt66Lm"
   },
   "outputs": [],
   "source": [
    "# https://medium.com/analytics-vidhya/tutorial-on-text-classification-nlp-using-ulmfit-and-fastai-library-in-python-2f15a2aac065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4091,
     "status": "ok",
     "timestamp": 1544014415532,
     "user": {
      "displayName": "이혜수",
      "photoUrl": "",
      "userId": "03058934578750168182"
     },
     "user_tz": -540
    },
    "id": "OPR30mr26poQ",
    "outputId": "b9f541e8-20fb-49a4-8d44-11819dd40de0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
      "Collecting torch_nightly\n",
      "\u001b[31m  Could not find a version that satisfies the requirement torch_nightly (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for torch_nightly\u001b[0m\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7529,
     "status": "ok",
     "timestamp": 1544014418978,
     "user": {
      "displayName": "이혜수",
      "photoUrl": "",
      "userId": "03058934578750168182"
     },
     "user_tz": -540
    },
    "id": "p7DgamNy6wiK",
    "outputId": "997d5d6a-8331-4044-d526-08ab609e6735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastai\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/12/b8c2374b15d5d77b28f4d09556510cf7b47bf2364d06913c97be633da7b0/fastai-1.0.42-py3-none-any.whl (162kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 688kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from fastai) (3.12)\n",
      "Collecting torchvision (from fastai)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 11.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting typing (from fastai)\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/bd/eee1157fc2d8514970b345d69cb9975dcd1e42cd7e61146ed841f6e68309/typing-3.6.6-py3-none-any.whl\n",
      "Collecting nvidia-ml-py3 (from fastai)\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/64/cce82bddb80c0b0f5c703bbdafa94bfb69a1c5ad7a79cff00b482468f0d3/nvidia-ml-py3-7.352.0.tar.gz\n",
      "Requirement already satisfied: requests in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from fastai) (2.18.4)\n",
      "Collecting spacy>=2.0.18 (from fastai)\n",
      "  Using cached https://files.pythonhosted.org/packages/19/c6/39b29bc6c6c94298e81624746cc69184c9cf064de24d8c40aa68f9eb8779/spacy-2.0.18-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Requirement already satisfied: scipy in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from fastai) (1.0.0)\n",
      "Collecting dataclasses; python_version < \"3.7\" (from fastai)\n",
      "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
      "Requirement already satisfied: pandas in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from fastai) (0.22.0)\n",
      "Collecting fastprogress>=0.1.18 (from fastai)\n",
      "  Downloading https://files.pythonhosted.org/packages/78/57/24a5e20f4a357f7f1c90dd5250071951c832b2480fd4fefd7be48edf4180/fastprogress-0.1.18-py3-none-any.whl\n",
      "Requirement already satisfied: Pillow in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from fastai) (5.1.0)\n",
      "Requirement already satisfied: matplotlib in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from fastai) (3.0.2)\n",
      "Collecting bottleneck (from fastai)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/ae/cedf5323f398ab4e4ff92d6c431a3e1c6a186f9b41ab3e8258dff786a290/Bottleneck-1.2.1.tar.gz (105kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 701kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting torch>=1.0.0 (from fastai)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/47/068dc7020fd8cf89cca74a16690e274fb55c08684bcaece11348d98264f0/torch-1.0.0-cp36-none-macosx_10_7_x86_64.whl (61.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 61.4MB 680kB/s eta 0:00:01    71% |██████████████████████▉         | 43.9MB 3.5MB/s eta 0:00:06\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from fastai) (4.5.3)\n",
      "Requirement already satisfied: packaging in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from fastai) (17.1)\n",
      "Requirement already satisfied: numexpr in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from fastai) (2.6.8)\n",
      "Requirement already satisfied: numpy>=1.12 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from fastai) (1.15.4)\n",
      "Requirement already satisfied: six in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from torchvision->fastai) (1.10.0)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from requests->fastai) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from requests->fastai) (1.22)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from requests->fastai) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from requests->fastai) (2018.1.18)\n",
      "Requirement already satisfied: ujson>=1.35 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from spacy>=2.0.18->fastai) (1.35)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from spacy>=2.0.18->fastai) (2.0.1)\n",
      "Collecting thinc<6.13.0,>=6.12.1 (from spacy>=2.0.18->fastai)\n",
      "  Using cached https://files.pythonhosted.org/packages/27/00/b2abd484bc4ef86e5c308acc6610e8f2c00c89b94701f42b9cc522ca70a4/thinc-6.12.1-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Requirement already satisfied: regex==2018.01.10 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from spacy>=2.0.18->fastai) (2018.1.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from spacy>=2.0.18->fastai) (2.0.2)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from spacy>=2.0.18->fastai) (0.2.8.2)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from spacy>=2.0.18->fastai) (0.9.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from spacy>=2.0.18->fastai) (0.28.0)\n",
      "Requirement already satisfied: python-dateutil>=2 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from pandas->fastai) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from pandas->fastai) (2018.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from matplotlib->fastai) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from matplotlib->fastai) (2.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from matplotlib->fastai) (1.0.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (4.24.0)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (1.10.11)\n",
      "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.5.6)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.9.0.1)\n",
      "Requirement already satisfied: msgpack-numpy<0.4.4 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.4.3.1)\n",
      "Requirement already satisfied: setuptools in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->fastai) (39.1.0)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.9.0)\n",
      "Building wheels for collected packages: nvidia-ml-py3, bottleneck\n",
      "  Running setup.py bdist_wheel for nvidia-ml-py3 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/grace/Library/Caches/pip/wheels/e4/1d/06/640c93f5270d67d0247f30be91f232700d19023f9e66d735c7\n",
      "  Running setup.py bdist_wheel for bottleneck ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/grace/Library/Caches/pip/wheels/f2/bf/ec/e0f39aa27001525ad455139ee57ec7d0776fe074dfd78c97e4\n",
      "Successfully built nvidia-ml-py3 bottleneck\n",
      "Installing collected packages: torch, torchvision, typing, nvidia-ml-py3, thinc, spacy, dataclasses, fastprogress, bottleneck, fastai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found existing installation: thinc 6.12.0\n",
      "    Uninstalling thinc-6.12.0:\n",
      "      Successfully uninstalled thinc-6.12.0\n",
      "  Found existing installation: spacy 2.0.16\n",
      "    Uninstalling spacy-2.0.16:\n",
      "      Successfully uninstalled spacy-2.0.16\n",
      "Successfully installed bottleneck-1.2.1 dataclasses-0.6 fastai-1.0.42 fastprogress-0.1.18 nvidia-ml-py3-7.352.0 spacy-2.0.18 thinc-6.12.1 torch-1.0.0 torchvision-0.2.1 typing-3.6.6\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10556,
     "status": "ok",
     "timestamp": 1544014422013,
     "user": {
      "displayName": "이혜수",
      "photoUrl": "",
      "userId": "03058934578750168182"
     },
     "user_tz": -540
    },
    "id": "uAZv0kOE8Daz",
    "outputId": "b6056d8e-a7ff-482a-8fa5-da58e76fff7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dataclasses in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (0.6)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install dataclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_qmw80Fu63op"
   },
   "outputs": [],
   "source": [
    "import fastai \n",
    "from fastai import * \n",
    "from fastai.text import * \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from functools import partial \n",
    "import io \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q01Pu_9K6_Fp"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups \n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove= \n",
    "                             ('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13398,
     "status": "ok",
     "timestamp": 1544014424877,
     "user": {
      "displayName": "이혜수",
      "photoUrl": "",
      "userId": "03058934578750168182"
     },
     "user_tz": -540
    },
    "id": "Uj5Ho6YmS5Hg",
    "outputId": "971c3028-949a-475f-bed0-8a088f58a269"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Well i'm not sure about the story nad it did seem biased. What\\nI disagree with is your statement that the U.S. Media is out to\\nruin Israels reputation. That is rediculous. The U.S. media is\\nthe most pro-israeli media in the world. Having lived in Europe\\nI realize that incidences such as the one described in the\\nletter have occured. The U.S. media as a whole seem to try to\\nignore them. The U.S. is subsidizing Israels existance and the\\nEuropeans are not (at least not to the same degree). So I think\\nthat might be a reason they report more clearly on the\\natrocities.\\n\\tWhat is a shame is that in Austria, daily reports of\\nthe inhuman acts commited by Israeli soldiers and the blessing\\nreceived from the Government makes some of the Holocaust guilt\\ngo away. After all, look how the Jews are treating other races\\nwhen they got power. It is unfortunate.\\n\",\n",
       " \"\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won't be bummin' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \\n--\\nBake Timmons, III\",\n",
       " \"Although I realize that principle is not one of your strongest\\npoints, I would still like to know why do do not ask any question\\nof this sort about the Arab countries.\\n\\n   If you want to continue this think tank charade of yours, your\\nfixation on Israel must stop.  You might have to start asking the\\nsame sort of questions of Arab countries as well.  You realize it\\nwould not work, as the Arab countries' treatment of Jews over the\\nlast several decades is so bad that your fixation on Israel would\\nbegin to look like the biased attack that it is.\\n\\n   Everyone in this group recognizes that your stupid 'Center for\\nPolicy Research' is nothing more than a fancy name for some bigot\\nwho hates Israel.\",\n",
       " 'Notwithstanding all the legitimate fuss about this proposal, how much\\nof a change is it?  ATT\\'s last product in this area (a) was priced over\\n$1000, as I suspect \\'clipper\\' phones will be; (b) came to the customer \\nwith the key automatically preregistered with government authorities. Thus,\\naside from attempting to further legitimize and solidify the fed\\'s posture,\\nClipper seems to be \"more of the same\", rather than a new direction.\\n   Yes, technology will eventually drive the cost down and thereby promote\\nmore widespread use- but at present, the man on the street is not going\\nto purchase a $1000 crypto telephone, especially when the guy on the other\\nend probably doesn\\'t have one anyway.  Am I missing something?\\n   The real question is what the gov will do in a year or two when air-\\ntight voice privacy on a phone line is as close as your nearest pc.  That\\nhas got to a problematic scenario for them, even if the extent of usage\\nnever surpasses the \\'underground\\' stature of PGP.',\n",
       " \"Well, I will have to change the scoring on my playoff pool.  Unfortunately\\nI don't have time right now, but I will certainly post the new scoring\\nrules by tomorrow.  Does it matter?  No, you'll enter anyway!!!  Good!\\n\\n--\\n    Keith Keller\\t\\t\\t\\tLET'S GO RANGERS!!!!!\\n\\t\\t\\t\\t\\t\\tLET'S GO QUAKERS!!!!!\\n\\tkkeller@mail.sas.upenn.edu\\t\\tIVY LEAGUE CHAMPS!!!!\",\n",
       " \" \\n \\nI read somewhere, I think in Morton Smith's _Jesus the Magician_, that\\nold Lazarus wasn't dead, but going in the tomb was part of an initiation\\nrite for a magi-cult, of which Jesus was also a part.   It appears that\\na 3-day stay was normal.   I wonder .... ?\",\n",
       " '\\nOk.  I have a record that shows a IIsi with and without a 64KB cache.\\nIt\\'s small enough that I will attach it.\\n\\nI have also measured some real programs with and without the 64 KB\\ncache.  The speedup varies a lot from app to app, ranging from 0% to\\n40%.  I think an average of 20%-25% is about right.  The subjective\\ndifference is not great, but is sometimes noticable.  A simple cache\\ncard certainly does not transform a IIsi into something enormously\\nbetter.  I do not have an FPU.\\n\\nThe conventional wisdom says that cache cards from all of the makers\\noffer about the same speedup and that there is not much difference\\nbetween 32K and 64K caches.  I bought mine from Third Wave for well\\nunder $150.  I have had absolutely no problems at all with it.\\n\\nIf you get *complete* speedometer runs for a 32K cache, I\\'d like to\\nsee them.  Let\\'s check the conventional wisdom!  The so called\\n\"Performance Rating\" numbers by themselves are of no interest. \\n\\nCheers.\\n\\n(This file must be converted with BinHex 4.0)\\n:#@0KBfKP,Q0`G!\"338083e\"$9!!!!!!\\'A!!!!!$qK3%\"a+!!!!BGJ&CfGiGfH(H\\n)GhQ!QSQBUC!!@SQUU(QSCfPhGhL(H+HCL&KjQTU)LDH)HBL*UCUCJ!U@GQ9hGiK\\nhCAKR9SPiJ)QRQ)QUJ+N(J!UCLD#U#S!!S!QUUTQC#U#DL3J)#3LT#UU)QUUBUT!\\n!S!L3!!UU#!QJS+UT!!QJS*UD#TUUQCQ3!*!!UCFJ!!%c4ACSL\\'D)L)D!#!!)#!!\\n!!!!!!!!)!!!!!!!!J!B8*%9@9L0A\"i!!G`!!G`B!!(J)\"i###B!P[US),B\")21Z\\n-1I\"k-cQFM-VXMHhA!irdjPcVr,lUCVSZ2SI8j@,-l,jPI`F#lZq0A\"AL8XRHjf,\\n6[LJ09\"aZ2TV6l!$9lN@eAP@Rei8(VIpIQkfDK$-ZV[b+9[T5lkC0XZ6LGhf(Ik&\\na$Lkh*Q6-qhh2MIlc*Q2Iq$p([GeSp(ejN!\"bHMdHll$&Qh\\'lR`E26C2(QBqSrMM\\npa-k()jPGXqcpR2rYR9eYd0,*Mh0,h1rj1*hA%pcLHRSG6PF2eIYmc4rIS60EFp+\\nCGE@Vr$[TRAFA(QkA`pG8JkS[@fe1mcBikFQC(,(9K[U&h\"\"0rr\"BDDT(i%XP3Z$\\nV04L8D82FeU01V4K-9U#JaD@1*fZa`EZr3-eGTYkNXH49SjF2Ei[G*5el3[VZ\\'j[\\nVf($bTBHjlEX3Pe0KJ8,ZKH!9Cc3+fJ%kHGZC*BHhNV9+DC6Xd$[S58DFD\"pJ%ei\\nq#CXHkEL`@d%&PYYY\"1f0rG`jm0rJTCYMi4B1KbB\\'pUBQ)PU9\\'q\"*m1miHG#YR`b\\neUNG1\\'mSAP#mR`i-1*K`l[DiNq\\'MQjZA(,4bq\"$*Mimq(KC9@@(-Mc\\'\"f88e9U&0\\nF\\'Y4U5eXb(\"+6T8D@6(R3ae+10Padk\"CAK!*Ea6SThLiA9HF!H&&Da@[,[2bA2!p\\n2VIr&TI)!6V`%S!*eJ#GS!Q!!QqD#2P!*M49m9IdHhm2frUq2Ek))G3e\"Vi)+rQJ\\nC[`%m#+E&0jf\"YI2ql`VI&0qHH!R[339`\\'9hY46)TR+ZkXI!pQRQKCU3%ed9R&Cr\\n!QCiUk+ZmEf)IYI&bqMEffkT5bB`JhYl2K[0PXVe0B@@2*@Uam121D`A`h+cC)Xl\\nIEjf8S+#9`a6[P8p0ZC&6H0ajcY1BR\"JDM3`F%lJ1&5bI+SC2Jh([qeTfVK961rR\\nZVIq[+Rb-TH3\\'B3f0r$h\\'\\'cP%\"UY1\\'jU53jY@5P(RCdPAXAfrl\"Xrhf#Y\"dmV1i$\\n9%Dm@T+f4NMlP5jd-XN0(K5C91\\'R@)4Qb9C5Ke1h%V-kiaRA-NTa`b9(YYL5TM5*\\nF2#bUFFLGJ%,D8QA*9R`eUQ29Sj!!p0b\\'\"c5LEFR4@%9KpDGj1,bijhNaDH,6mrm\\n(3qpJITeraM0+0RHJ*aJ%f`#HJ!R4JJXDK22e!Cab5DK)jkRq0r[IcrC`[c!Krd(\\n$m1VrbJCX!NR)3FrcHYPk(r1CHJjiJ#Hk%\\'J84pq+#+$a2&r&bZ,Ff1V,-KG6qG9\\nMbmUPG9XkUeX$2Gl!Gl!Gl!GE!k5hrX(F4IX4IRNYkb\"M%rSbN4`8m8qPq2rAd[j\\nFhRC#4(PeI2RFhY0+j-GH\\'!P*S)h!#HN!R6JJXb5f\\'b!clJkfb121qGm2MclEe,S\\nmHpf12b4arQ$Q%%PLK\"q(8@I8[qRmmS5[l`\"2fP!\"4CpjY0,DDAp2AlE#eIPBD0c\\nrL1,PeXj39[%9k`HF4Z,ZKGN4h9A+b-T23l)RDf\\'a13X\"\\'-#VbKJ[!9ME*!Tlp2-\\nQckRpM@J2e5BN*f&jHN*[Vp-#f+F(J)PQXJNlYRLpQ3C,%`Cm0l3E[MP\"cXZ6`)B\\nmpVS0)P3Y@XTB5F5qaSr\"XrmrZf1iLXSV,pPVjICFMRrekXdDI`0FHmT[Q!4VL`T\\naalM336chGUr@\"Me6YarIDI&Y2LpE9HPaI#fhNFmq$qLchVC(dUajJ%eb%(6NdIH\\np#jqEd#X1cGDTVmDY965+@Pi,Mr1JeR&pq`q@\"AacVkC[0lZi3-Z-5PZk8%f$Vrd\\nHfR&1mci,3&Nqh9r\"e%\"j5Ve$0rN`AbfB\"Qqlk$C`3@LKQRh0(-MKhNYA+UC&Qhq\\n5kajHR1eFqR,2H5b8Z!SLfG3!!2TPmiF!!3!+58PcD5eMB@0SC3%!!!!)6@0S9(0\\n3C$1R$)JJT`b+33%!ADmicJ!#!!!4a3!!!!!!!!B9!!!!!,AP!!!:\\n-- ',\n",
       " \"\\n\\n\\nSounds like wishful guessing.\\n\\n\\n\\n\\n'So-called' ? What do you mean ? How would you see the peace process?\\n\\nSo you say palestineans do not negociate because of 'well-founded' predictions ?\\nHow do you know that they are 'well founded' if you do not test them at the \\ntable ? 18 months did not prove anything, but it's always the other side at \\nfault, right ?\\n\\nWhy ? I do not know why, but if, let's say, the Palestineans (some of them) want\\nALL ISRAEL, and these are known not to be accepted terms by israelis.\\n\\nOr, maybe they (palestinenans) are not yet ready for statehood ?\\n\\nOr, maybe there is too much politics within the palestinean leadership, too many\\nfractions aso ?\\n\\nI am not saying that one of these reasons is indeed the real one, but any of\\nthese could make arabs stall the negotiations.\\n\\n \\nI like California oranges. And the feelings may get sharper at the table.\\n\\n\\n\\nRegards,\",\n",
       " \" Nobody is saying that you shouldn't be allowed to use msg.  Just\\ndon't force it on others. If you have food that you want to \\nenhance with msg just put the MSG on the table like salt.  It is\\nthen the option of the eater to use it.  If you make a commerical\\nproduct, just leave it out. You can include a packet (like some\\nsalt packets) if you desire.\\n\\nSalt, pepper, mustard, ketchup, pickles ..... are table options.\\nTreat MSG the same way.  I wouldn't shove my condiments down your\\nthroat, don't shove yours down mine.\\n\\nWFL\\n\",\n",
       " \"\\n  I was wondering if anyone can shed any light on just how it is that these\\nelectronic odometers remember the total elapsed mileage?  What kind of\\nmemory is stable/reliable enough, non-volatile enough and independent enough\\n(of outside battery power) to last say, 10 years or more, in the life of a\\nvehicle?  I'm amazed that anything like this could be expected to work for\\nthis length of time (especially in light of all the gizmos I work with that\\nare doing good to work for 2 months without breaking down somehow).\\n\\nSide question:  how about the legal ramifications of selling a used car with\\na replaced odometer that starts over at 0 miles, after say 100/200/300K\\nactual miles.  Looks like fraud would be fairly easy - for the price of a\\nnew odometer, you can say it has however many miles you want to tell the\\nbuyer it has.\\n\\nThanks for any insight.\\n\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13391,
     "status": "ok",
     "timestamp": 1544014424877,
     "user": {
      "displayName": "이혜수",
      "photoUrl": "",
      "userId": "03058934578750168182"
     },
     "user_tz": -540
    },
    "id": "jRq2VVia6_VR",
    "outputId": "edd0e1b6-549e-4f2e-ba5c-9f6d32425e9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'label':dataset.target, 'text':dataset.data})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13383,
     "status": "ok",
     "timestamp": 1544014424877,
     "user": {
      "displayName": "이혜수",
      "photoUrl": "",
      "userId": "03058934578750168182"
     },
     "user_tz": -540
    },
    "id": "PONkpkhbZs1z",
    "outputId": "60865463-d1de-4f55-9fb4-575f91b295b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>Well i'm not sure about the story nad it did s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>Although I realize that principle is not one o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>Notwithstanding all the legitimate fuss about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Well, I will have to change the scoring on my ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0     17  Well i'm not sure about the story nad it did s...\n",
       "1      0  \\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...\n",
       "2     17  Although I realize that principle is not one o...\n",
       "3     11  Notwithstanding all the legitimate fuss about ...\n",
       "4     10  Well, I will have to change the scoring on my ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vSIcLK167Anh"
   },
   "outputs": [],
   "source": [
    "# #df = df[df['label'].isin([1,10])] \n",
    "# df = df[df['label']<10]\n",
    "# df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 718,
     "status": "ok",
     "timestamp": 1544015088671,
     "user": {
      "displayName": "이혜수",
      "photoUrl": "",
      "userId": "03058934578750168182"
     },
     "user_tz": -540
    },
    "id": "ZPu7PAkZ7B3Z",
    "outputId": "2be26e24-7d51-4cf5-df24-41ffa822b824"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    600\n",
       "15    599\n",
       "8     598\n",
       "9     597\n",
       "11    595\n",
       "13    594\n",
       "7     594\n",
       "14    593\n",
       "5     593\n",
       "12    591\n",
       "2     591\n",
       "3     590\n",
       "6     585\n",
       "1     584\n",
       "4     578\n",
       "17    564\n",
       "16    546\n",
       "0     480\n",
       "18    465\n",
       "19    377\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ulE-TM0m7C_B"
   },
   "outputs": [],
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C7TCp_Ce7FZJ"
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace(\"[^a-zA-Z]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1207,
     "status": "ok",
     "timestamp": 1544015089187,
     "user": {
      "displayName": "이혜수",
      "photoUrl": "",
      "userId": "03058934578750168182"
     },
     "user_tz": -540
    },
    "id": "C9YMqlE6aIKG",
    "outputId": "8f4bd1b0-a6d6-479a-9563-2202c898f606"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>Well i m not sure about the story nad it did s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Yeah  do you expect people to read the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>Although I realize that principle is not one o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>Notwithstanding all the legitimate fuss about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Well  I will have to change the scoring on my ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0     17  Well i m not sure about the story nad it did s...\n",
       "1      0         Yeah  do you expect people to read the ...\n",
       "2     17  Although I realize that principle is not one o...\n",
       "3     11  Notwithstanding all the legitimate fuss about ...\n",
       "4     10  Well  I will have to change the scoring on my ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4230,
     "status": "ok",
     "timestamp": 1544015092219,
     "user": {
      "displayName": "이혜수",
      "photoUrl": "",
      "userId": "03058934578750168182"
     },
     "user_tz": -540
    },
    "id": "Bg-9lxDo8JTZ",
    "outputId": "68b8f097-9f5a-4f91-aca3-e2cef44f3df5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (3.3)\n",
      "Requirement already satisfied: six in /Users/grace/workspace/keras/venv/lib/python3.6/site-packages (from nltk) (1.10.0)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7925,
     "status": "ok",
     "timestamp": 1544015095921,
     "user": {
      "displayName": "이혜수",
      "photoUrl": "",
      "userId": "03058934578750168182"
     },
     "user_tz": -540
    },
    "id": "OnPDSaQz7FwK",
    "outputId": "d92ebcd4-3a39-491a-afc0-50d28e88622d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/grace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('stopwords') \n",
    "from nltk.corpus import stopwords \n",
    "stop_words = stopwords.words('english')\n",
    "# tokenization \n",
    "tokenized_doc = df['text'].apply(lambda x: x.split()) \n",
    "# remove stop-words \n",
    "tokenized_doc = tokenized_doc.apply(lambda x:[item for item in x if \n",
    "                                    item not in stop_words]) \n",
    "\n",
    "# de-tokenization \n",
    "detokenized_doc = [] \n",
    "for i in range(len(df)):\n",
    "    t =' '.join(tokenized_doc[i]) \n",
    "    detokenized_doc.append(t) \n",
    "df['text'] = detokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7918,
     "status": "ok",
     "timestamp": 1544015095921,
     "user": {
      "displayName": "이혜수",
      "photoUrl": "",
      "userId": "03058934578750168182"
     },
     "user_tz": -540
    },
    "id": "50sMDlfJ7HkI",
    "outputId": "63747c83-2d0b-417f-b7ed-f47be8b0f0f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6788, 2), (4526, 2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "# split data into training and validation set \n",
    "df_trn, df_val = train_test_split(df, stratify = df['label'], \n",
    "                                  test_size = 0.4, \n",
    "                                  random_state = 12)\n",
    "df_trn.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6g4UK9Zv7Ky5"
   },
   "outputs": [],
   "source": [
    "# Language model data \n",
    "data_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = \n",
    "                                  df_val, path = \"\") \n",
    "# Classifier model data \n",
    "data_clas = TextClasDataBunch.from_df(path = \"\", train_df = df_trn, \n",
    "                                      valid_df = df_val,  \n",
    "                                      vocab=data_lm.train_ds.vocab, \n",
    "                                      bs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hX08FOe27NMQ"
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, pretrained_model=URLs.WT103,  \n",
    "                               drop_mult=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 107893,
     "status": "ok",
     "timestamp": 1544015195916,
     "user": {
      "displayName": "이혜수",
      "photoUrl": "",
      "userId": "03058934578750168182"
     },
     "user_tz": -540
    },
    "id": "kEriUMLp7PlI",
    "outputId": "b745c460-c03c-45e5-c444-5195bb3778d0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 1:04:37 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>6.262411</th>\n",
       "    <th>5.749133</th>\n",
       "    <th>0.221036</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the learner object with learning rate = 1e-2 \n",
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1MmR-lX67RL4"
   },
   "outputs": [],
   "source": [
    "learn.save_encoder('ft_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4roAehrR7Tcg"
   },
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_clas, drop_mult=0.7) \n",
    "learn.load_encoder('ft_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 292145,
     "status": "ok",
     "timestamp": 1544015380189,
     "user": {
      "displayName": "이혜수",
      "photoUrl": "",
      "userId": "03058934578750168182"
     },
     "user_tz": -540
    },
    "id": "i2Q9M39U7UgI",
    "outputId": "506345fd-9a40-4daf-9fc3-fe1747930f6e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 45:56 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>2.590875</th>\n",
       "    <th>2.203593</th>\n",
       "    <th>0.304905</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1544015418127,
     "user": {
      "displayName": "이혜수",
      "photoUrl": "",
      "userId": "03058934578750168182"
     },
     "user_tz": -540
    },
    "id": "3VJ8yveT7WEg",
    "outputId": "b04a822e-79c2-46d8-c80e-9001e6d02503"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>55</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>43</td>\n",
       "      <td>120</td>\n",
       "      <td>86</td>\n",
       "      <td>11</td>\n",
       "      <td>58</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>48</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>118</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>76</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>119</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>176</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>69</td>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>109</td>\n",
       "      <td>99</td>\n",
       "      <td>74</td>\n",
       "      <td>78</td>\n",
       "      <td>61</td>\n",
       "      <td>126</td>\n",
       "      <td>100</td>\n",
       "      <td>233</td>\n",
       "      <td>84</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>137</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   0   1   2    3   4    5   6   7    8    9    10  11  12   13   14  \\\n",
       "row_0                                                                       \n",
       "1        0   0   0    0   0    0   0   0    0    0    0   0   0    0    1   \n",
       "2        0  37  55   34  38   23  17   1    2    1    0   6  27    1    3   \n",
       "3        0  28  43  120  86   11  58   7    1    0    0   9  46    0    2   \n",
       "4        0   0   0    0   3    0   3   0    1    0    0   0   2    0    1   \n",
       "5        1  79  48   21  19  118   6   3    3    1    0  23  24    9    5   \n",
       "6        1  16  21   10  13    6  76  12   13    3    3   7  10    2    4   \n",
       "7        0   2   0    2   8    0   7  75   70    0    0   0  10    0    8   \n",
       "8        0   0   1    0   0    0   0   7   15    0    0   0   0    0    1   \n",
       "9        0   0   0    1   0    1   0   4    2   11    6   0   0    0    3   \n",
       "10       0   1   0    0   0    1   7   2    2  119  153   0   1    0    2   \n",
       "11       1   2   3    1   4    5   4   2    2    0    0  94  18    1    4   \n",
       "12       0   1   0    4   4    0   2   5    4    0    0   3  24    0   10   \n",
       "13       0   0   1    0   0    2   2   3    0    0    0   0   2   95    2   \n",
       "14       0   1   0    0   1    0   0   0    1    0    0   0   1    1   76   \n",
       "15     176  64  62   40  50   69  45  98  109   99   74  78  61  126  100   \n",
       "16       1   0   0    0   0    0   1   5    2    0    0   9   3    0    3   \n",
       "17      11   3   2    2   5    1   4  12   11    5    3   5   7    2    7   \n",
       "18       1   0   0    1   0    0   2   2    1    0    1   4   0    1    5   \n",
       "\n",
       "col_0   15  16   17   18   19  \n",
       "row_0                          \n",
       "1        0   0    0    0    0  \n",
       "2        0   2    0    0    0  \n",
       "3        0   1    0    0    0  \n",
       "4        0   0    0    0    0  \n",
       "5        3   0    2    0    0  \n",
       "6        0   4    1    1    0  \n",
       "7        0   1    0    1    0  \n",
       "8        0   1    0    0    0  \n",
       "9        0   1    0    0    0  \n",
       "10       0   1    1    3    1  \n",
       "11       0   8    0    4    2  \n",
       "12       0   0    0    0    0  \n",
       "13       0   1    1    4    1  \n",
       "14       0   3    0    0    0  \n",
       "15     233  84   80  128  130  \n",
       "16       1  66    0    6    5  \n",
       "17       3  37  137   10   11  \n",
       "18       0   8    4   29    1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get predictions \n",
    "preds, targets = learn.get_preds() \n",
    "predictions = np.argmax(preds, axis = 1) \n",
    "pd.crosstab(predictions, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5FLKEqxx7XWh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ULMFiT_test.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
