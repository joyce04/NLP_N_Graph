{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate string matching with FuzzyWuzzy\n",
    "\n",
    "- FuzzyWuzzy is a python library uses Levenstein Distance to calculate the differences between sequences\n",
    "- following https://github.com/seatgeek/fuzzywuzzy\n",
    "- and https://towardsdatascience.com/natural-language-processing-for-fuzzy-string-matching-with-python-6632b7824c49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import db_conn\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio compare the entire string similarity in order\n",
    "fuzz.ratio('mesna', 'mesnex')\n",
    "# 73 = 73% similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial_ratio compares partial string similarity\n",
    "fuzz.partial_ratio('I love computer science', 'computer programming is what I love the most')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_sort_ratio : ignores word order\n",
    "fuzz.token_sort_ratio('I love computer science', 'computer programming is what I love the most')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_set_ratio : ignores duplicate words\n",
    "fuzz.token_set_ratio('I love computer science', 'computer programming is what I love the most')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_set_ratio : ignores duplicate words\n",
    "fuzz.token_set_ratio('I love computer science', 'computer programming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if conn:\n",
    "# conn.close()\n",
    "conn = db_conn.CONN\n",
    "cursor = conn.cursor(pymysql.cursors.DictCursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get drug list from dictionary table\n",
    "cursor.execute('SELECT * FROM dict_collapsed_final')\n",
    "drugs = pd.DataFrame(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cui1 와 cui2 string을 비교하기 = 연습으로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## token_set_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs['fuzzy_perc'] = drugs.apply(lambda x: \\\n",
    "                                  fuzz.token_set_ratio(x['cui1_str'], x['cui2_str']),\\\n",
    "                                axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아예 같은 약물이 아닌, 일부 스펠링이 다른 경우 어느 정도의 약물을 같은 약물로 판단할 수 있을 것인가\n",
    "drugs[(drugs.fuzzy_perc>70) & (drugs.fuzzy_perc<100)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs[(drugs.fuzzy_perc<50)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample table -> sentence file\n",
    "sents = []\n",
    "with open('./new_sample_data_m.txt', 'r') as file:\n",
    "    for line in file.readlines():\n",
    "        if(line.find('***')<0):\n",
    "            sents.append(line.strip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_gtl_80 = []\n",
    "for d in drugs.cui1_str.unique():\n",
    "    for sen in sents:\n",
    "        fuzz_ratio = fuzz.token_set_ratio(d, sen)\n",
    "        if fuzz_ratio >= 80:\n",
    "            similarity_gtl_80.append({'drug':d, 'sen':sen, 'ratio':fuzz_ratio})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim_gtl_80 = pd.DataFrame(similarity_gtl_80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim_gtl_80.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim_gtl_80.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "df_sim_gtl_80[df_sim_gtl_80.ratio<100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs.loc[(drugs.cui1_str=='zinc acetate') | (drugs.cui2_str=='zinc acetate')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs.loc[(drugs.cui1_str=='abiraterone acetate') | (drugs.cui2_str=='abiraterone acetate')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs.loc[(drugs.cui1_str.str.find('sipul')>=0) | (drugs.cui2_str.str.find('sipul')>=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = ['I love computer science', 'COMPUTER SCIENCE', 'computer programming', 'programming IT']\n",
    "process.extract('computer science', choices, limit=3, scorer=fuzz.token_set_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_gtl_80_extract = []\n",
    "for d in drugs.cui1_str.unique():\n",
    "    sens = process.extract(d, sents, limit=3, scorer=fuzz.token_set_ratio)\n",
    "    if len(sens) >=0 :\n",
    "        similarity_gtl_80_extract.append({d:sens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for pair in similarity_gtl_80_extract:\n",
    "    d = list(pair.keys())[0]\n",
    "    above_80 = list(map(lambda x: {'drug':d, 'sen':x[0], 'perc':x[1]}, filter(lambda x: x[1] > 80, pair[d])))\n",
    "    if len(above_80)>0:\n",
    "        pairs.extend(above_80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pairs).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_count = 6000\n",
    "retrieve_strip_html = \"\"\"select strip_tags(content) as c, table_title, id \n",
    "                        from research.article_tables \n",
    "                        order by id\n",
    "                        limit 1000 offset %s\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "#  %%pixie_debugger\n",
    "\n",
    "possible_drugs = []\n",
    "for c in range(70):\n",
    "    print(c*1000)\n",
    "    print(retrieve_strip_html % (c*1000))\n",
    "    cursor.execute(retrieve_strip_html % (c*1000))\n",
    "    result = list(cursor.fetchall())\n",
    "\n",
    "    for d in drugs.cui1_str.unique():#['sipuleucel-t']:#\n",
    "    #     cursor.execute(check_query % (\"'%\"+d[:-cut_len]+\"%'\", \"'%\"+d+\"%'\"))\n",
    "        fuzz_r = 0\n",
    "        for r in result:\n",
    "            rc = r['c'].replace('\\n', ' ')\n",
    "            fuzz_r = fuzz.partial_token_set_ratio(d, rc)\n",
    "            if fuzz_r >= 80 and fuzz_r<100:\n",
    "                \n",
    "                words = list(filter(lambda x:x.strip() and len(x.strip())>5, rc.split(' ')))\n",
    "                best_words = process.extractBests(d, words, limit=2, scorer=fuzz.token_set_ratio)\n",
    "                p_drugs = list(filter(lambda x: x[1]>=70, best_words))\n",
    "                if len(p_drugs)>0:\n",
    "                    print(d, r['table_title'])\n",
    "                    print('\\t' + str(p_drugs))\n",
    "                    possible_drugs.extend(list(map(lambda x:{'drug':d, 'p_drug':x[0], 'id':r['id'], 'ratio':x[1]}, p_drugs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_dr = pd.DataFrame(possible_drugs)\n",
    "df_pos_dr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_dr.drop_duplicates(subset=['p_drug'], inplace=True)\n",
    "df_pos_dr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dr in df_pos_dr[:3].iterrows():\n",
    "    print(dr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_dict = []\n",
    "for dr in df_pos_dr.iterrows():\n",
    "    dr_ = '%'+dr[1]['p_drug'].lower().strip()\\\n",
    "            .replace('(', '').replace(',', '').replace(':', '').replace('+', '').replace(';', '')\\\n",
    "            .replace('.', '').replace(')', '')+'%'\n",
    "    cursor.execute(\"select * from dict_collapsed_final where lower(cui1_str) like '%s' or lower(cui2_str) like '%s';\" % (dr_, dr_))\n",
    "    already_in = cursor.fetchall()\n",
    "    if len(already_in) ==0 and dr_.replace('%', '') not in ['otherwise', 'fathers', 'other','maintenance', 'father', 'dosing' ,'maintenance']:\n",
    "        print(dr_.replace('%', ''))\n",
    "        not_in_dict.append({'drug':dr_.replace('%', '').strip(), 'id':dr[1]['id']})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
